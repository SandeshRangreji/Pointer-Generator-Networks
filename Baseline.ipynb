{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Baseline(from scratch).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandeshRangreji/Pointer-Generator-Networks/blob/main/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFe8Tuv1j1Vf",
        "outputId": "20fc0d80-0128-4793-eac4-29195a58caa1"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 22 09:04:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB66MTa6j-zW",
        "outputId": "5312f06d-487a-4b16-a9dd-cd81a7f9d563"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIOujJRQFsjR",
        "outputId": "90d69e37-f6d9-41ba-cf00-8c517dccfd44"
      },
      "source": [
        "pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ROq-CnaCxiy",
        "outputId": "20802996-8ac3-4150-8f32-553d47f45b40"
      },
      "source": [
        "pip install --upgrade tensorflow-lattice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-lattice in /usr/local/lib/python3.7/dist-packages (2.0.8)\n",
            "Requirement already satisfied, skipping upgrade: sklearn in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: dm-sonnet in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->tensorflow-lattice) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (0.8.9)\n",
            "Requirement already satisfied, skipping upgrade: dm-tree>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (0.1.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow-lattice) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->tensorflow-lattice) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->tensorflow-lattice) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVJ2Zjl2e13P"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_lattice as tfl\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GypFb5xFgL-S",
        "outputId": "5063a751-cab0-4429-81ca-4b9de2a561b1"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd8EHJ67go_u",
        "outputId": "9fbd9709-2b36-4863-bbdb-1d9c0b8ebf22"
      },
      "source": [
        "# unzips Glove word embeddings\n",
        "!unrar x \"/content/drive/MyDrive/Pointer Generator Networks/glove.6B.300d.rar\" -d \"/content/PGN/data/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/Pointer Generator Networks/glove.6B.300d.rar\n",
            "\n",
            "Creating    /content/PGN                                              OK\n",
            "Creating    /content/PGN/data                                         OK\n",
            "Extracting  /content/PGN/data/glove.6B.300d.txt                          \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G88GzsYIcz5n"
      },
      "source": [
        "VAL_NUM_EXAMPLES = 8192"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5gXu4Z1lEOz"
      },
      "source": [
        "# class to handle data loading, splitting, preprocessing, tokenization\n",
        "class Data:\n",
        "\n",
        "  def __init__(self, vocab_size, oov_token):\n",
        "    # dictionary for contractions\n",
        "    self.tokenizer = Tokenizer(num_words = vocab_size, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token=oov_token)\n",
        "    self.contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "  # function to perform contractions\n",
        "  def split_contractions(self, sentence):\n",
        "    # parameters:\n",
        "    # sentence: article/summary (string)\n",
        "    # making a list of words from the article/summary\n",
        "    # return: article/summary after contractions (string)\n",
        "    li_sentence = sentence.split(' ')\n",
        "    # iterating through each word and replacing the contracted word if it is present in contraction dictionary\n",
        "    for i in range(len(li_sentence)):\n",
        "      li_sentence[i] = self.contractions.get(li_sentence[i], li_sentence[i])\n",
        "    # combining the list to form a string again\n",
        "    sentence = ' '.join(li_sentence)\n",
        "    return sentence\n",
        "\n",
        "  # function to handle preprocessing of articles and summaries\n",
        "  def preprocess(self, sentence):\n",
        "    # parameters:\n",
        "    # sentence: article or summary to be processed\n",
        "    # returns:\n",
        "    # sentence: cleaned article/summary\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    sentence = self.split_contractions(sentence)\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = \"<sos> \" + sentence\n",
        "    sentence = sentence.replace(\" . \", \" <sos> <eos> \")\n",
        "    sentence = sentence[:len(sentence) - 7]\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    # removing trailing spaces\n",
        "    sentence = sentence.lower().strip()\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence  \n",
        "  \n",
        "  # splitting data into articles and summaries for training and testing\n",
        "  def split_data(self, dataset):\n",
        "    # parameters:\n",
        "    # dataset : tfds of cnn_dailymail dataset (bytes)\n",
        "    # returns:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (string)\n",
        "    train_articles = []\n",
        "    train_summaries = []\n",
        "    eval_articles = []\n",
        "    eval_summaries = []\n",
        "    # iterating through train dataset and storing articles and summaries seperately\n",
        "    for text in tfds.as_numpy(dataset['train']):\n",
        "      # decoding from bytes to string\n",
        "      article = self.preprocess(text['article'].decode(\"utf-8\"))\n",
        "      summaries = self.preprocess(text['highlights'].decode(\"utf-8\"))\n",
        "      train_articles.append(article)\n",
        "      train_summaries.append(summaries)\n",
        "\n",
        "    # iterating through validation dataset and storing articles and summaries seperately\n",
        "    for text in tfds.as_numpy(dataset['validation']):\n",
        "      # decoding from bytes to string\n",
        "      article = self.preprocess(text['article'].decode(\"utf-8\"))\n",
        "      summaries = self.preprocess(text['highlights'].decode(\"utf-8\"))\n",
        "      eval_articles.append(article)\n",
        "      eval_summaries.append(summaries)\n",
        "    return train_articles, train_summaries, eval_articles, eval_summaries\n",
        "\n",
        "  # function to tokenize data\n",
        "  def tokenize(self, train_articles, train_summaries, eval_articles, eval_summaries, vocab_size , embedding_dim, max_length_articles, max_length_summaries, truncating_type, padding_type, oov_token):\n",
        "    # parameters:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (string)\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimensions of word embeddings\n",
        "    # max_lengths_articles: number of words in the longest article\n",
        "    # max_lengths_summaries: number of words in the longest summary\n",
        "    # truncating_type: pre/post truncatation\n",
        "    # padding_type: pro/post padding\n",
        "    # oov_token: specifies what oov_token should be used\n",
        "    # return:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (sequences)\n",
        "    # initialize tokenizer\n",
        "    # fit tokenizer on training input (vocab)\n",
        "    self.tokenizer.fit_on_texts(train_articles)\n",
        "    # get word index from tokenizer\n",
        "    word_index = self.tokenizer.word_index\n",
        "    # tokenize articles for training \n",
        "    train_articles = self.tokenizer.texts_to_sequences(train_articles)\n",
        "    train_articles = pad_sequences(train_articles ,maxlen=max_length_articles, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize summaries for training \n",
        "    eval_articles = self.tokenizer.texts_to_sequences(eval_articles)\n",
        "    eval_articles = pad_sequences(eval_articles, maxlen=max_length_articles, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize articles for eval \n",
        "    train_summaries = self.tokenizer.texts_to_sequences(train_summaries)\n",
        "    train_summaries = pad_sequences(train_summaries ,maxlen=max_length_summaries, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize summaries for eval \n",
        "    eval_summaries = self.tokenizer.texts_to_sequences(eval_summaries)\n",
        "    eval_summaries = pad_sequences(eval_summaries, maxlen=max_length_summaries, padding=padding_type, truncating=truncating_type)\n",
        "    return train_articles, train_summaries, eval_articles, eval_summaries, word_index\n",
        "\n",
        "  # function to get a dictionery which is the reverse of the word_index\n",
        "  def get_reverse_word_index(self, word_index):\n",
        "    # parameters:\n",
        "    # word_index : { word : id }\n",
        "    # returns\n",
        "    # reverse_word_index : { id : word }\n",
        "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "    return reverse_word_index\n",
        "\n",
        "  # get important metrics of the dataset that is needed to build a model\n",
        "  def get_data_metrics(self):\n",
        "    # return:\n",
        "    # average length of articles, average length of summaries, length of longest article, length of longest summary\n",
        "    # loading dataset\n",
        "    ds = tfds.load(\"cnn_dailymail\")\n",
        "    # decoding and splitting dataset into train and eval articles and summaries\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries = self.split_data(ds)\n",
        "    train_article_sum = 0\n",
        "    max_article_len = 0\n",
        "    max_summary_len = 0\n",
        "    train_summaries_sum = 0\n",
        "    # iterating through dataset to count total number of words\n",
        "    for i in range(len(train_articles)):\n",
        "      # current article and summary length (no. of words)\n",
        "      article_len = len(train_articles[i].split())\n",
        "      summary_len = len(train_summaries[i].split())\n",
        "      # finding length of article with most number of words\n",
        "      if(article_len>max_article_len):\n",
        "        max_article_len = article_len\n",
        "      # finding length of summary with most number of words\n",
        "      if(summary_len>max_summary_len):\n",
        "        max_summary_len = summary_len\n",
        "      # calculating total number of words accross all articles and summary to calculate average\n",
        "      train_article_sum = train_article_sum + article_len\n",
        "      train_summaries_sum = train_summaries_sum + summary_len\n",
        "    return train_article_sum/len(train_articles), train_summaries_sum/len(train_summaries), max_article_len, max_summary_len \n",
        "\n",
        "  # function to load pretrained word embeddings and prepare them for embedding layer\n",
        "  def get_word_embeddings(self, word_index, vocab_size, embedding_dim):\n",
        "    # parameters:\n",
        "    # word_index: { word:id }\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimension of word embeddings\n",
        "    embeddings_index = {}\n",
        "    # opening and reading word embeddings from file\n",
        "    with open('/content/PGN/data/glove.6B.' + str(embedding_dim) + 'd.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "\n",
        "    # converting word embeddings to matrix (weights for embedding layer) using word_index\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None and i<=vocab_size:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "    return embeddings_index, embeddings_matrix\n",
        "\n",
        "  # function to convert list of articles and summaries to iterable, batched datasets\n",
        "  def batch_datasets(self, train_articles, train_summaries, eval_articles, eval_summaries, BATCH_SIZE):\n",
        "    # parameters:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (sequences)\n",
        "    # BATCH_SIZE: size of one batch in the dataset\n",
        "    # return:\n",
        "    # train_dataset, val_dataset: dataset objects for training and evaluation, batched according to BATCH_SIZE\n",
        "    # making a dataset object from the train articles and summaries\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_articles, train_summaries))\n",
        "    # batching training dataset\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    # making a dataset object from the evaluation articles and summaries\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((eval_articles, eval_summaries))\n",
        "    # batching evaluation dataset\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "  def __call__(self, num_training_examples = 2048, vocab_size = 25000, embedding_dim = 200, max_length_articles = 2880, max_length_summaries = 1344, truncating_type='post', padding_type='post', oov_token='<OOV>', BATCH_SIZE=64):\n",
        "    # parameters:\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimensions of word embeddings\n",
        "    # max_lengths_articles: number of words in the longest article\n",
        "    # max_lengths_summaries: number of words in the longest summary\n",
        "    # truncating_type: pre/post truncatation\n",
        "    # padding_type: pro/post padding\n",
        "    # oov_token: specifies what oov_token should be used\n",
        "    # returns:\n",
        "    # train_dataset, val_dataset: dataset objects for training and evaluation, batched according to BATCH_SIZE\n",
        "    # word_index : { word : id }\n",
        "    # reverse_word_index : { id : word }\n",
        "\n",
        "    # loading data in bytes from tfds\n",
        "    ds=tfds.load(\"cnn_dailymail\", shuffle_files = False)\n",
        "    # splitting data into train and test sets of articles and summaries\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries = self.split_data(ds)\n",
        "    # tokenizing data\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries, word_index = self.tokenize(\n",
        "        train_articles[:num_training_examples], \n",
        "        train_summaries[:num_training_examples], \n",
        "        eval_articles[:VAL_NUM_EXAMPLES], \n",
        "        eval_summaries[:VAL_NUM_EXAMPLES],\n",
        "        vocab_size , \n",
        "        embedding_dim, \n",
        "        max_length_articles, \n",
        "        max_length_summaries, \n",
        "        truncating_type, \n",
        "        padding_type, \n",
        "        oov_token)\n",
        "    # vocab_size = len(word_index)\n",
        "    # converting list of articles to train and evaluation datasets that are in batches\n",
        "    train_dataset, validation_dataset = self.batch_datasets(train_articles, train_summaries, eval_articles, eval_summaries, BATCH_SIZE)\n",
        "    return train_dataset, validation_dataset, word_index, self.get_reverse_word_index(word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OehanrRoj_u"
      },
      "source": [
        "vocab_size = 50000\n",
        "num_examples = 32000\n",
        "# num_examples = 16000\n",
        "embedding_dim = 300\n",
        "max_length_articles = 512\n",
        "max_length_summaries = 128\n",
        "truncating_type ='post'\n",
        "padding_type ='post'\n",
        "oov_token = \"<OOV>\"\n",
        "BATCH_SIZE = 16\n",
        "data = Data(vocab_size, oov_token)\n",
        "# load, split, batch data\n",
        "train_dataset, val_dataset, word_index, reverse_word_index = data(\n",
        "        num_examples,\n",
        "        vocab_size, \n",
        "        embedding_dim, \n",
        "        max_length_articles, \n",
        "        max_length_summaries, \n",
        "        truncating_type, \n",
        "        padding_type, \n",
        "        oov_token,\n",
        "        BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBMPgFoEqxhD"
      },
      "source": [
        "# get word embeddings in the form of a matrix\n",
        "embeddings_index, embeddings_matrix = data.get_word_embeddings(word_index, vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzIxZw99RuAy",
        "outputId": "8926bc9e-520e-43ba-e24f-46699ed56978"
      },
      "source": [
        "embeddings_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3nKYCnZ7Tdw",
        "outputId": "8f180af0-72d6-4704-e308-07ef1deb7a12"
      },
      "source": [
        "# sample data from dataset\n",
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([16, 512]), TensorShape([16, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJcHSb8Apscl"
      },
      "source": [
        "# class for Encoder model\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, embeddings_matrix, hidden_dim):\n",
        "    # parameters:\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dims: dimension of word embeddings\n",
        "    # enc_units: number of LSTM units in the encoder\n",
        "    # batch_sz: batch size of data\n",
        "    # embedding_matrix: word embeddings in the form of a matrix\n",
        "    super(Encoder, self).__init__()\n",
        "    # initializing model layers and some parameters of those layers\n",
        "    self.batch_sz = batch_sz\n",
        "    self.l1_enc_units = enc_units\n",
        "    self.l2_enc_units = enc_units//2\n",
        "    self.l3_enc_units = enc_units//4\n",
        "    # initializing embedding layer with pretrained word embeddings\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length_articles, weights=[embeddings_matrix], trainable=False)\n",
        "\n",
        "    ##________ LSTM layer in Encoder ------- ##\n",
        "    self.lstm_layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l1_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    self.lstm_layer_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l2_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    self.lstm_layer_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l3_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    self.reduce_h = tf.keras.layers.Dense(units = hidden_dim, use_bias=True)\n",
        "    self.reduce_c = tf.keras.layers.Dense(units = hidden_dim, use_bias=True)\n",
        "\n",
        "\n",
        "  # build encoder model\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output_1, forward_h1, forward_c1, backward_h1, backward_c1 = self.lstm_layer_1(x, initial_state = hidden )\n",
        "    output_2, forward_h2, forward_c2, backward_h2, backward_c2 = self.lstm_layer_2(output_1)\n",
        "    output_3, forward_h3, forward_c3, backward_h3, backward_c3 = self.lstm_layer_3(output_2)\n",
        "    # h = tf.concat([forward_h1, backward_h1], axis=-1)\n",
        "    # c = tf.concat([forward_c1, backward_c1], axis=-1)\n",
        "    # h = tf.concat([forward_h2, backward_h2], axis=-1)\n",
        "    # c = tf.concat([forward_c2, backward_c2], axis=-1)\n",
        "    h = tf.concat([forward_h3, backward_h3], axis=-1)\n",
        "    c = tf.concat([forward_c3, backward_c3], axis=-1)\n",
        "    final_h = tf.keras.activations.relu(self.reduce_h(h))\n",
        "    final_c = tf.keras.activations.relu(self.reduce_c(c))\n",
        "    return output_3, final_h, final_c\n",
        "\n",
        "  # initializing weights\n",
        "  def initialize_hidden_state(self):\n",
        "    return [tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE2MZNq7px80",
        "outputId": "8943a1b1-2bcb-459f-c6bf-c47fea9a0770"
      },
      "source": [
        "## Test Encoder Stack\n",
        "\n",
        "units = 256\n",
        "# dec_units = units//2\n",
        "dec_units = units\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE, embeddings_matrix, dec_units)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder h vector shape: (batch size, units) {}'.format(sample_h.shape))\n",
        "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (16, 512, 128)\n",
            "Encoder h vector shape: (batch size, units) (16, 256)\n",
            "Encoder c vector shape: (batch size, units) (16, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0YP1g30zPV2"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.v = tf.keras.layers.Dense(units = 1, use_bias=False)                       # v\n",
        "    self.enc_proj = tf.keras.layers.Dense(units = hidden_dim*2, use_bias=False)      # W_h\n",
        "    self.dec_proj = tf.keras.layers.Dense(units = hidden_dim*2, use_bias=True)        # W_s, b_attn\n",
        "    self.w_c = tf.keras.layers.Dense(units = hidden_dim*2 , use_bias=False)                     # W_c\n",
        "\n",
        "  def __call__(self, dec_input, coverage, enc_hidden):\n",
        "    enc_feature = self.enc_proj(enc_hidden)         # [B x L x 2H]\n",
        "    dec_feature = self.dec_proj(dec_input)          # [B x 2H]\n",
        "    dec_feature = tf.expand_dims(dec_feature, 1)    # [B x 1 x 2H]\n",
        "    # print(enc_feature.shape)\n",
        "    # print(dec_feature.shape)\n",
        "    scores = enc_feature + dec_feature              # [B x L x 2H]\n",
        "\n",
        "    coverage = tf.expand_dims(coverage, -1)      # [B x L x 1]\n",
        "    cov_feature = self.w_c(coverage)            # [B x L x 2H]\n",
        "    scores = scores + cov_feature\n",
        "\n",
        "    scores = tf.keras.activations.tanh(scores)                     # [B x L x 2H]\n",
        "    scores = self.v(scores)                         # [B x L x 1]\n",
        "    scores = tf.squeeze(scores, -1)                     # [B x L]\n",
        "    attn_dist = tf.keras.activations.softmax(scores, axis = -1)               # [B x L]\n",
        "    return attn_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMfuORfuD4dz",
        "outputId": "31ff4714-d182-4363-f06c-c257f96df5e5"
      },
      "source": [
        "attention = Attention(dec_units)\n",
        "coverage = np.random.randn(BATCH_SIZE, max_length_articles)\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, dec_units))\n",
        "attn_dist = attention(sample_x, coverage, sample_output)\n",
        "print(attn_dist.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvwhGVczp85q"
      },
      "source": [
        "class PointerGenerator(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(PointerGenerator, self).__init__()\n",
        "    self.w_h = tf.keras.layers.Dense(units = 1, use_bias=False) \n",
        "    self.w_s = tf.keras.layers.Dense(units = 1, use_bias=False) \n",
        "    self.w_x = tf.keras.layers.Dense(units = 1, use_bias=True) \n",
        "\n",
        "  def call(self, context_vec, dec_input, outputs, vocab_dist, attn_dist):\n",
        "    # Eq. (8) - Compute generation probability p_gen\n",
        "    context_feat = self.w_h(context_vec)                    # [B x 1]\n",
        "    decoder_feat = self.w_s(outputs)                              # [B x 1]\n",
        "    input_feat = self.w_x(dec_input)                          # [B x 1]\n",
        "    \n",
        "    gen_feat = context_feat + decoder_feat + input_feat\n",
        "    p_gen = tf.keras.activations.sigmoid(gen_feat)                            # [B x 1]\n",
        "\n",
        "    # Eq. (9) - Compute prob dist'n over extended vocabulary\n",
        "    vocab_dist = p_gen * vocab_dist                         # [B x V]\n",
        "    weighted_attn_dist = (1.0 - p_gen) * attn_dist          # [B x L]\n",
        "    return weighted_attn_dist, vocab_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z64oJe-zqBLQ"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    # Embedding Layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    # Define the fundamental cell for decoder recurrent structure\n",
        "    self.rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
        "    # Define the attention layer\n",
        "    self.attention = Attention(self.dec_units)\n",
        "    # Define the Pointer Generator \n",
        "    # self.pointerGen = PointerGenerator()\n",
        "    # Fully Connected layers\n",
        "    self.v = tf.keras.layers.Dense(units = dec_units, use_bias=True)   # V, b\n",
        "    self.v_out = tf.keras.layers.Dense(units = vocab_size, use_bias=True)   # V', b'\n",
        "    \n",
        "  def initialize_hidden_state(self, batch_sz, sample_h, sample_c):\n",
        "    return [sample_h, sample_c]\n",
        "\n",
        "  def embedding(self, input):\n",
        "    return self.embedding(input)\n",
        "\n",
        "  def __call__(self, x, hidden, cov, enc_output, indices):  \n",
        "    # print(\"In decoder\")\n",
        "    hidden, cell = self.rnn_cell(x, hidden)\n",
        "    attn_dist = self.attention(hidden, cov, enc_output)\n",
        "    # The context vector is used later to compute generation probability\n",
        "    context_vec = tf.linalg.matmul(tf.expand_dims(attn_dist, 1), enc_output)   # [B x 1 x 2H]\n",
        "    context_vec = tf.math.reduce_sum(context_vec, axis = 1)                    # [B x 2H] \n",
        "    # Eq. (4)\n",
        "    output = self.v(tf.concat([hidden, context_vec], axis=-1))                # [B x 3H] -> [B x H]\n",
        "    output = self.v_out(output)                                                # [B x V]\n",
        "    vocab_dist = tf.keras.activations.softmax(output, axis=-1)                 # [B x V]\n",
        "    return vocab_dist, attn_dist, context_vec, output, cell[0], cell[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liyPdtoz7Wfl",
        "outputId": "479efb5a-b7c7-43ba-bf89-d831a550885f"
      },
      "source": [
        "# Test decoder stack\n",
        "decoder = Decoder(vocab_size, embedding_dim, dec_units, BATCH_SIZE)\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, embedding_dim))\n",
        "hidden = decoder.initialize_hidden_state(BATCH_SIZE, sample_h, sample_c)\n",
        "cov_sample = np.zeros((BATCH_SIZE, max_length_articles))\n",
        "# sample_x = decoder.embedding(sample_x)\n",
        "vocab_dist, attn_dist, context_vec, sample_decoder_outputs, dec_h, dec_c = decoder(sample_x, hidden, cov_sample, sample_output, example_input_batch)\n",
        "\n",
        "# pointerGen = PointerGenerator()\n",
        "print(\"Vocab Distribution Shape: \", vocab_dist.shape)\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.shape)\n",
        "# print(\"LSTM Outputs Shape: \", sample_lstm_out.shape)\n",
        "print(\"Decoder hidden state Shape: \", dec_h.shape)\n",
        "print(\"Decoder cell state Shape: \", dec_c.shape)\n",
        "print(\"Attention Distribution Shape: \", attn_dist.shape)\n",
        "print(\"Context Vector Shape: \", context_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Distribution Shape:  (16, 50000)\n",
            "Decoder Outputs Shape:  (16, 50000)\n",
            "Decoder hidden state Shape:  (16, 256)\n",
            "Decoder cell state Shape:  (16, 256)\n",
            "Attention Distribution Shape:  (16, 512)\n",
            "Context Vector Shape:  (16, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7iZyk9kqLoP"
      },
      "source": [
        "def scatter_add(tensor, indices, updates):\n",
        "    original_tensor = tensor\n",
        "    # expand index value from vocab size\n",
        "    indices = tf.compat.v1.reshape(indices, shape=[-1, tf.shape(indices)[-1]])\n",
        "    indices_add = tf.compat.v1.expand_dims(tf.range(0, tf.shape(indices)[0], 1)*(tf.shape(tensor)[-1]), axis=-1)\n",
        "    indices += indices_add\n",
        "\n",
        "    # resize\n",
        "    tensor = tf.compat.v1.reshape(tensor, shape=[-1])\n",
        "    indices = tf.compat.v1.reshape(indices, shape=[-1, 1])\n",
        "    updates = tf.compat.v1.reshape(updates, shape=[-1])\n",
        "\n",
        "    # check_\n",
        "    \"\"\"\n",
        "    update = tensor.shape[indices.shape[-1]:]\n",
        "    res = indices.shape[:-1] + update\n",
        "    \"\"\"\n",
        "    # same Torch scatter_add_\n",
        "    scatter = tf.compat.v1.tensor_scatter_nd_add(tensor, indices, updates)\n",
        "    scatter = tf.compat.v1.reshape(scatter, shape=[tf.shape(original_tensor)[0], tf.shape(original_tensor)[1], -1])\n",
        "    return scatter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4nDlcp7zVxL"
      },
      "source": [
        "initial_learning_rate = 0.001\n",
        "# step = tf.Variable(0, trainable=False)\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate,\n",
        "#     decay_steps=(num_examples//BATCH_SIZE) * 10,\n",
        "#     decay_rate=1.00,\n",
        "#     staircase=True)\n",
        "# wd = lambda: 1e-4 * lr_schedule(step)\n",
        "# optimizer = tfa.optimizers.AdamW(learning_rate=lr_schedule, clipnorm=1.0, weight_decay=wd)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss\n",
        "\n",
        "def coverage_loss(attn_dist, coverage):\n",
        "  min_val = tf.math.minimum(attn_dist, coverage)   # [B x L x T]   \n",
        "  loss = tf.math.reduce_sum(min_val, axis=1)            # [B x T]\n",
        "  avg_loss = tf.math.reduce_sum(loss) / (BATCH_SIZE * max_length_summaries)\n",
        "  return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJIeF-m65Wzv"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JgVFBL0NDJU"
      },
      "source": [
        "# saving weights\n",
        "def save_weights_in_drive(epoch):\n",
        "  if epoch!= 1:\n",
        "    os.remove(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-\" + str(epoch-1) + \".data-00000-of-00001\")\n",
        "    os.remove(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-\" + str(epoch-1) + \".index\")\n",
        "  shutil.copy2(\"/content/training_checkpoints/checkpoint\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  shutil.copy2(\"/content/training_checkpoints/ckpt-\" + str(epoch) + \".data-00000-of-00001\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  shutil.copy2(\"/content/training_checkpoints/ckpt-\" + str(epoch) + \".index\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  # shutil.copy2(\"/content/drive/MyDrive/Pointer Generator Networks/coverage_weights.npy\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXZblk5dqPp4"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden, cov):\n",
        "  loss = 0\n",
        "  cov_loss = 0\n",
        "  cov_weight = 1.0\n",
        "  # 3 lists\n",
        "  final_dists = []\n",
        "  attn_dists = []\n",
        "  coverages = []\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "    dec_inp = targ[ : , :-1 ]   # Ignore <end> token\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\n",
        "    dec_h = enc_h\n",
        "    dec_c = enc_c\n",
        "    dec_emb = decoder.embedding(dec_inp)\n",
        "    cov = tf.zeros([BATCH_SIZE, max_length_articles], tf.float32)\n",
        "    for t in range(max_length_summaries-1):\n",
        "      decoder_initial_state = decoder.initialize_hidden_state(BATCH_SIZE, dec_h, dec_c)\n",
        "      input_t = dec_emb[:, t, :] \n",
        "      vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(input_t, decoder_initial_state, cov, enc_output, inp)\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "      final_dists.append(vocab_dist)\n",
        "      attn_dists.append(attn_dist)\n",
        "      coverages.append(cov)\n",
        "    final_dists = tf.stack(final_dists, axis=-1)\n",
        "    attn_dists = tf.stack(attn_dists, axis=-1)\n",
        "    coverages = tf.stack(coverages, axis=-1)\n",
        "    final_dists = tf.reshape(final_dists, [BATCH_SIZE, max_length_summaries-1, vocab_size])\n",
        "\n",
        "    logits = final_dists\n",
        "    loss = loss_function(real, logits)\n",
        "    cov_loss = coverage_loss(attn_dist, cov)\n",
        "    loss = loss + cov_weight * cov_loss\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables), experimental_aggregate_gradients=False)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_odmwqx9Rf1Y"
      },
      "source": [
        "@tf.function\n",
        "def eval_step(inp, targ, enc_hidden, cov):\n",
        "  loss = 0\n",
        "  cov_loss = 0\n",
        "  cov_weight = 1.0\n",
        "  # 3 lists\n",
        "  final_dists = []\n",
        "  attn_dists = []\n",
        "  coverages = []\n",
        "  encoder.trainable = False\n",
        "  decoder.trainable = False\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "    dec_inp = targ[ : , :-1 ]   # Ignore <end> token\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\n",
        "    dec_h = enc_h\n",
        "    dec_c = enc_c\n",
        "    dec_emb = decoder.embedding(dec_inp)\n",
        "    cov = tf.zeros([BATCH_SIZE, max_length_articles], tf.float32)\n",
        "\n",
        "    for t in range(max_length_summaries-1):\n",
        "      decoder_initial_state = decoder.initialize_hidden_state(BATCH_SIZE, dec_h, dec_c)\n",
        "      input_t = dec_emb[:, t, :] \n",
        "      vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(input_t, decoder_initial_state, cov, enc_output, inp)\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "\n",
        "      final_dists.append(vocab_dist)\n",
        "      attn_dists.append(attn_dist)\n",
        "      coverages.append(cov)\n",
        "    final_dists = tf.stack(final_dists, axis=-1)\n",
        "    attn_dists = tf.stack(attn_dists, axis=-1)\n",
        "    coverages = tf.stack(coverages, axis=-1)\n",
        "    final_dists = tf.reshape(final_dists, [BATCH_SIZE, max_length_summaries-1, vocab_size])\n",
        "\n",
        "    logits = final_dists\n",
        "    loss = loss_function(real, logits)\n",
        "    cov_loss = coverage_loss(attn_dist, cov)\n",
        "    loss = loss + cov_weight * cov_loss\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables), experimental_aggregate_gradients=False)\n",
        "\n",
        "  encoder.trainable = True\n",
        "  decoder.trainable = True\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO5TQMAkqTJ4",
        "outputId": "eb4403c2-f16f-491b-a50d-d12a5ef98b8f"
      },
      "source": [
        "EPOCHS = 40\n",
        "count = 1\n",
        "steps_per_epoch = num_examples//BATCH_SIZE\n",
        "val_steps_per_epoch = VAL_NUM_EXAMPLES//BATCH_SIZE\n",
        "# steps_per_epoch = 1\n",
        "if count == 1:\n",
        "  cov = np.zeros((BATCH_SIZE, max_length_articles))\n",
        "else:\n",
        "  cov = np.load(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/coverage_weights.npy\")\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  val_total_loss = 0\n",
        "  # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden, cov)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print('Epoch {} Batch {} Loss {}'.format(count,\n",
        "                                                   batch,\n",
        "                                                   batch_loss))\n",
        "\n",
        "  for (val_batch, (val_inp, val_targ)) in enumerate(val_dataset.take(val_steps_per_epoch)):\n",
        "    val_batch_loss = eval_step(val_inp, val_targ, enc_hidden, cov)\n",
        "    val_total_loss += val_batch_loss\n",
        "  \n",
        "  # saving (checkpoint) the model every epoch\n",
        "  if (epoch + 1) % 1 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {}'.format(count,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Epoch {} Validation Loss {}'.format(count,\n",
        "                                      val_total_loss / val_steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  # print(\"Learning Rate: \" + str(optimizer.lr.initial_learning_rate))\n",
        "  train_losses.append(total_loss / steps_per_epoch)\n",
        "  eval_losses.append(val_total_loss / val_steps_per_epoch)\n",
        "  np.save(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/coverage_weights\", cov)\n",
        "  save_weights_in_drive(count)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.31657075881958\n",
            "Epoch 1 Batch 400 Loss 2.8432254791259766\n",
            "Epoch 1 Batch 800 Loss 3.4499623775482178\n",
            "Epoch 1 Batch 1200 Loss 2.9157235622406006\n",
            "Epoch 1 Batch 1600 Loss 3.2047290802001953\n",
            "Epoch 1 Loss 3.1850829124450684\n",
            "Epoch 1 Validation Loss 3.4659030437469482\n",
            "Time taken for 1 epoch 1241.9245703220367 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 3.5041544437408447\n",
            "Epoch 2 Batch 400 Loss 2.7395734786987305\n",
            "Epoch 2 Batch 800 Loss 3.3657095432281494\n",
            "Epoch 2 Batch 1200 Loss 2.8484952449798584\n",
            "Epoch 2 Batch 1600 Loss 3.1485507488250732\n",
            "Epoch 2 Loss 3.0733017921447754\n",
            "Epoch 2 Validation Loss 3.4336225986480713\n",
            "Time taken for 1 epoch 1187.2241184711456 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 3.4371817111968994\n",
            "Epoch 3 Batch 400 Loss 2.675050735473633\n",
            "Epoch 3 Batch 800 Loss 3.306058406829834\n",
            "Epoch 3 Batch 1200 Loss 2.795741558074951\n",
            "Epoch 3 Batch 1600 Loss 3.096811294555664\n",
            "Epoch 3 Loss 3.013291835784912\n",
            "Epoch 3 Validation Loss 3.409167528152466\n",
            "Time taken for 1 epoch 1187.1924374103546 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 3.3622474670410156\n",
            "Epoch 4 Batch 400 Loss 2.6427478790283203\n",
            "Epoch 4 Batch 800 Loss 3.2490804195404053\n",
            "Epoch 4 Batch 1200 Loss 2.7479043006896973\n",
            "Epoch 4 Batch 1600 Loss 3.1290345191955566\n",
            "Epoch 4 Loss 2.9923410415649414\n",
            "Epoch 4 Validation Loss 3.4543256759643555\n",
            "Time taken for 1 epoch 1186.71240401268 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 3.375559091567993\n",
            "Epoch 5 Batch 400 Loss 2.64306902885437\n",
            "Epoch 5 Batch 800 Loss 3.265421152114868\n",
            "Epoch 5 Batch 1200 Loss 2.756944179534912\n",
            "Epoch 5 Batch 1600 Loss 3.0521481037139893\n",
            "Epoch 5 Loss 2.96555757522583\n",
            "Epoch 5 Validation Loss 3.406181573867798\n",
            "Time taken for 1 epoch 1185.398978471756 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 3.290252923965454\n",
            "Epoch 6 Batch 400 Loss 2.617133378982544\n",
            "Epoch 6 Batch 800 Loss 3.2191786766052246\n",
            "Epoch 6 Batch 1200 Loss 2.725278854370117\n",
            "Epoch 6 Batch 1600 Loss 3.01936674118042\n",
            "Epoch 6 Loss 2.9356327056884766\n",
            "Epoch 6 Validation Loss 3.393831253051758\n",
            "Time taken for 1 epoch 1185.9380421638489 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 3.2552695274353027\n",
            "Epoch 7 Batch 400 Loss 2.543124198913574\n",
            "Epoch 7 Batch 800 Loss 3.1531565189361572\n",
            "Epoch 7 Batch 1200 Loss 2.678239583969116\n",
            "Epoch 7 Batch 1600 Loss 2.975844621658325\n",
            "Epoch 7 Loss 2.8774867057800293\n",
            "Epoch 7 Validation Loss 3.374340295791626\n",
            "Time taken for 1 epoch 1186.394385099411 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 3.2055675983428955\n",
            "Epoch 8 Batch 400 Loss 2.5088188648223877\n",
            "Epoch 8 Batch 800 Loss 3.1159846782684326\n",
            "Epoch 8 Batch 1200 Loss 2.645451784133911\n",
            "Epoch 8 Batch 1600 Loss 2.938732624053955\n",
            "Epoch 8 Loss 2.846193552017212\n",
            "Epoch 8 Validation Loss 3.363970994949341\n",
            "Time taken for 1 epoch 1186.7420063018799 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 3.17047381401062\n",
            "Epoch 9 Batch 400 Loss 2.4612958431243896\n",
            "Epoch 9 Batch 800 Loss 3.0678117275238037\n",
            "Epoch 9 Batch 1200 Loss 2.6129941940307617\n",
            "Epoch 9 Batch 1600 Loss 2.894395112991333\n",
            "Epoch 9 Loss 2.8016371726989746\n",
            "Epoch 9 Validation Loss 3.341041326522827\n",
            "Time taken for 1 epoch 1186.5029063224792 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 3.1252684593200684\n",
            "Epoch 10 Batch 400 Loss 2.4305717945098877\n",
            "Epoch 10 Batch 800 Loss 3.0320305824279785\n",
            "Epoch 10 Batch 1200 Loss 2.5819671154022217\n",
            "Epoch 10 Batch 1600 Loss 2.8772902488708496\n",
            "Epoch 10 Loss 2.7697975635528564\n",
            "Epoch 10 Validation Loss 3.331512928009033\n",
            "Time taken for 1 epoch 1186.318440437317 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 3.087001323699951\n",
            "Epoch 11 Batch 400 Loss 2.401414394378662\n",
            "Epoch 11 Batch 800 Loss 2.9958090782165527\n",
            "Epoch 11 Batch 1200 Loss 2.55621075630188\n",
            "Epoch 11 Batch 1600 Loss 2.8415074348449707\n",
            "Epoch 11 Loss 2.741227388381958\n",
            "Epoch 11 Validation Loss 3.3216822147369385\n",
            "Time taken for 1 epoch 1186.2275013923645 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 3.060835123062134\n",
            "Epoch 12 Batch 400 Loss 2.3804609775543213\n",
            "Epoch 12 Batch 800 Loss 2.9681179523468018\n",
            "Epoch 12 Batch 1200 Loss 2.5361428260803223\n",
            "Epoch 12 Batch 1600 Loss 2.8181004524230957\n",
            "Epoch 12 Loss 2.712369918823242\n",
            "Epoch 12 Validation Loss 3.3168187141418457\n",
            "Time taken for 1 epoch 1186.5768337249756 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 3.0257556438446045\n",
            "Epoch 13 Batch 400 Loss 2.357870101928711\n",
            "Epoch 13 Batch 800 Loss 2.9369301795959473\n",
            "Epoch 13 Batch 1200 Loss 2.5166306495666504\n",
            "Epoch 13 Batch 1600 Loss 2.792339324951172\n",
            "Epoch 13 Loss 2.6878693103790283\n",
            "Epoch 13 Validation Loss 3.3153562545776367\n",
            "Time taken for 1 epoch 1186.4376389980316 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 2.9949679374694824\n",
            "Epoch 14 Batch 400 Loss 2.355320453643799\n",
            "Epoch 14 Batch 800 Loss 2.911848545074463\n",
            "Epoch 14 Batch 1200 Loss 2.492513418197632\n",
            "Epoch 14 Batch 1600 Loss 2.812868118286133\n",
            "Epoch 14 Loss 2.671466827392578\n",
            "Epoch 14 Validation Loss 3.3151395320892334\n",
            "Time taken for 1 epoch 1185.8629729747772 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 2.970928907394409\n",
            "Epoch 15 Batch 400 Loss 2.314084768295288\n",
            "Epoch 15 Batch 800 Loss 2.899951934814453\n",
            "Epoch 15 Batch 1200 Loss 2.586454153060913\n",
            "Epoch 15 Batch 1600 Loss 2.7660083770751953\n",
            "Epoch 15 Loss 2.6457254886627197\n",
            "Epoch 15 Validation Loss 3.313673257827759\n",
            "Time taken for 1 epoch 1185.563244342804 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 2.95379638671875\n",
            "Epoch 16 Batch 400 Loss 2.296785831451416\n",
            "Epoch 16 Batch 800 Loss 2.8731627464294434\n",
            "Epoch 16 Batch 1200 Loss 2.4692533016204834\n",
            "Epoch 16 Batch 1600 Loss 2.7521986961364746\n",
            "Epoch 16 Loss 2.6300175189971924\n",
            "Epoch 16 Validation Loss 3.3110668659210205\n",
            "Time taken for 1 epoch 1185.36971783638 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 2.927168130874634\n",
            "Epoch 17 Batch 400 Loss 2.271228790283203\n",
            "Epoch 17 Batch 800 Loss 2.863781213760376\n",
            "Epoch 17 Batch 1200 Loss 2.4584357738494873\n",
            "Epoch 17 Batch 1600 Loss 2.735849142074585\n",
            "Epoch 17 Loss 2.612708330154419\n",
            "Epoch 17 Validation Loss 3.3139190673828125\n",
            "Time taken for 1 epoch 1185.1705458164215 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 2.9043238162994385\n",
            "Epoch 18 Batch 400 Loss 2.2653937339782715\n",
            "Epoch 18 Batch 800 Loss 2.871617317199707\n",
            "Epoch 18 Batch 1200 Loss 2.700739622116089\n",
            "Epoch 18 Batch 1600 Loss 2.730109214782715\n",
            "Epoch 18 Loss 2.615445852279663\n",
            "Epoch 18 Validation Loss 3.309018135070801\n",
            "Time taken for 1 epoch 1185.7125296592712 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 2.8931326866149902\n",
            "Epoch 19 Batch 400 Loss 2.2614974975585938\n",
            "Epoch 19 Batch 800 Loss 2.8359928131103516\n",
            "Epoch 19 Batch 1200 Loss 2.446333408355713\n",
            "Epoch 19 Batch 1600 Loss 2.7159557342529297\n",
            "Epoch 19 Loss 2.5789525508880615\n",
            "Epoch 19 Validation Loss 3.310195207595825\n",
            "Time taken for 1 epoch 1185.7324719429016 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 2.878704071044922\n",
            "Epoch 20 Batch 400 Loss 2.241913318634033\n",
            "Epoch 20 Batch 800 Loss 2.8054635524749756\n",
            "Epoch 20 Batch 1200 Loss 2.4242634773254395\n",
            "Epoch 20 Batch 1600 Loss 2.69765305519104\n",
            "Epoch 20 Loss 2.5550999641418457\n",
            "Epoch 20 Validation Loss 3.313688039779663\n",
            "Time taken for 1 epoch 1185.5975315570831 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 2.8551619052886963\n",
            "Epoch 21 Batch 400 Loss 2.2580478191375732\n",
            "Epoch 21 Batch 800 Loss 2.790093183517456\n",
            "Epoch 21 Batch 1200 Loss 2.44057297706604\n",
            "Epoch 21 Batch 1600 Loss 2.7028985023498535\n",
            "Epoch 21 Loss 2.5830836296081543\n",
            "Epoch 21 Validation Loss 3.319704055786133\n",
            "Time taken for 1 epoch 1186.5872359275818 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 2.850020408630371\n",
            "Epoch 22 Batch 400 Loss 2.231992721557617\n",
            "Epoch 22 Batch 800 Loss 2.7714409828186035\n",
            "Epoch 22 Batch 1200 Loss 2.385997772216797\n",
            "Epoch 22 Batch 1600 Loss 2.6745007038116455\n",
            "Epoch 22 Loss 2.5323097705841064\n",
            "Epoch 22 Validation Loss 3.322329521179199\n",
            "Time taken for 1 epoch 1185.7975046634674 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 2.8289971351623535\n",
            "Epoch 23 Batch 400 Loss 2.2081668376922607\n",
            "Epoch 23 Batch 800 Loss 2.754124641418457\n",
            "Epoch 23 Batch 1200 Loss 2.369717836380005\n",
            "Epoch 23 Batch 1600 Loss 2.6614112854003906\n",
            "Epoch 23 Loss 2.513245105743408\n",
            "Epoch 23 Validation Loss 3.3234617710113525\n",
            "Time taken for 1 epoch 1185.5243606567383 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 2.8085217475891113\n",
            "Epoch 24 Batch 400 Loss 2.1952850818634033\n",
            "Epoch 24 Batch 800 Loss 2.7528460025787354\n",
            "Epoch 24 Batch 1200 Loss 2.405221462249756\n",
            "Epoch 24 Batch 1600 Loss 2.6509456634521484\n",
            "Epoch 24 Loss 2.505979537963867\n",
            "Epoch 24 Validation Loss 3.3277719020843506\n",
            "Time taken for 1 epoch 1185.7651076316833 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 2.7928545475006104\n",
            "Epoch 25 Batch 400 Loss 2.193434715270996\n",
            "Epoch 25 Batch 800 Loss 2.7424278259277344\n",
            "Epoch 25 Batch 1200 Loss 2.3485617637634277\n",
            "Epoch 25 Batch 1600 Loss 2.639209270477295\n",
            "Epoch 25 Loss 2.500189781188965\n",
            "Epoch 25 Validation Loss 3.3269755840301514\n",
            "Time taken for 1 epoch 1185.685805797577 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 2.787846565246582\n",
            "Epoch 26 Batch 400 Loss 2.2074780464172363\n",
            "Epoch 26 Batch 800 Loss 2.7301995754241943\n",
            "Epoch 26 Batch 1200 Loss 2.959578275680542\n",
            "Epoch 26 Batch 1600 Loss 3.152946949005127\n",
            "Epoch 26 Loss 2.761319637298584\n",
            "Epoch 26 Validation Loss 3.5398783683776855\n",
            "Time taken for 1 epoch 1185.6206951141357 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 3.3855204582214355\n",
            "Epoch 27 Batch 400 Loss 2.6597414016723633\n",
            "Epoch 27 Batch 800 Loss 3.2856860160827637\n",
            "Epoch 27 Batch 1200 Loss 2.7649500370025635\n",
            "Epoch 27 Batch 1600 Loss 3.0620830059051514\n",
            "Epoch 27 Loss 2.9840338230133057\n",
            "Epoch 27 Validation Loss 3.4885289669036865\n",
            "Time taken for 1 epoch 1185.9493367671967 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 3.273911476135254\n",
            "Epoch 28 Batch 400 Loss 2.5770065784454346\n",
            "Epoch 28 Batch 800 Loss 3.19895601272583\n",
            "Epoch 28 Batch 1200 Loss 2.7028300762176514\n",
            "Epoch 28 Batch 1600 Loss 3.0098118782043457\n",
            "Epoch 28 Loss 2.906298875808716\n",
            "Epoch 28 Validation Loss 3.479048252105713\n",
            "Time taken for 1 epoch 1185.9093041419983 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 3.2203238010406494\n",
            "Epoch 29 Batch 400 Loss 2.513432741165161\n",
            "Epoch 29 Batch 800 Loss 3.111724376678467\n",
            "Epoch 29 Batch 1200 Loss 2.648050308227539\n",
            "Epoch 29 Batch 1600 Loss 2.9470136165618896\n",
            "Epoch 29 Loss 2.8351876735687256\n",
            "Epoch 29 Validation Loss 3.450077772140503\n",
            "Time taken for 1 epoch 1185.685842037201 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 3.1375949382781982\n",
            "Epoch 30 Batch 400 Loss 2.4589481353759766\n",
            "Epoch 30 Batch 800 Loss 3.0301544666290283\n",
            "Epoch 30 Batch 1200 Loss 2.601846933364868\n",
            "Epoch 30 Batch 1600 Loss 2.911017656326294\n",
            "Epoch 30 Loss 2.767228603363037\n",
            "Epoch 30 Validation Loss 3.433758497238159\n",
            "Time taken for 1 epoch 1185.2412722110748 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 3.082365036010742\n",
            "Epoch 31 Batch 400 Loss 2.3947839736938477\n",
            "Epoch 31 Batch 800 Loss 2.982285976409912\n",
            "Epoch 31 Batch 1200 Loss 2.5454938411712646\n",
            "Epoch 31 Batch 1600 Loss 2.827291965484619\n",
            "Epoch 31 Loss 2.7066051959991455\n",
            "Epoch 31 Validation Loss 3.4042277336120605\n",
            "Time taken for 1 epoch 1185.5682489871979 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 2.9990663528442383\n",
            "Epoch 32 Batch 400 Loss 2.336362838745117\n",
            "Epoch 32 Batch 800 Loss 2.9019663333892822\n",
            "Epoch 32 Batch 1200 Loss 2.4978413581848145\n",
            "Epoch 32 Batch 1600 Loss 2.8083064556121826\n",
            "Epoch 32 Loss 2.657000780105591\n",
            "Epoch 32 Validation Loss 3.4005544185638428\n",
            "Time taken for 1 epoch 1186.1091797351837 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 2.9625356197357178\n",
            "Epoch 33 Batch 400 Loss 2.441624164581299\n",
            "Epoch 33 Batch 800 Loss 3.208859920501709\n",
            "Epoch 33 Batch 1200 Loss 2.5015461444854736\n",
            "Epoch 33 Batch 1600 Loss 2.7709028720855713\n",
            "Epoch 33 Loss 2.7382986545562744\n",
            "Epoch 33 Validation Loss 3.3895347118377686\n",
            "Time taken for 1 epoch 1186.1878411769867 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 2.9493818283081055\n",
            "Epoch 34 Batch 400 Loss 2.294726610183716\n",
            "Epoch 34 Batch 800 Loss 3.197389602661133\n",
            "Epoch 34 Batch 1200 Loss 2.6215920448303223\n",
            "Epoch 34 Batch 1600 Loss 2.8776981830596924\n",
            "Epoch 34 Loss 2.7606351375579834\n",
            "Epoch 34 Validation Loss 3.4425199031829834\n",
            "Time taken for 1 epoch 1185.792091846466 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 3.061598062515259\n",
            "Epoch 35 Batch 400 Loss 2.3527655601501465\n",
            "Epoch 35 Batch 800 Loss 2.9666919708251953\n",
            "Epoch 35 Batch 1200 Loss 2.4762485027313232\n",
            "Epoch 35 Batch 1600 Loss 2.760432720184326\n",
            "Epoch 35 Loss 2.653984546661377\n",
            "Epoch 35 Validation Loss 3.36387300491333\n",
            "Time taken for 1 epoch 1186.186271429062 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 2.900860071182251\n",
            "Epoch 36 Batch 400 Loss 2.2703232765197754\n",
            "Epoch 36 Batch 800 Loss 2.8935649394989014\n",
            "Epoch 36 Batch 1200 Loss 2.4300577640533447\n",
            "Epoch 36 Batch 1600 Loss 2.8485970497131348\n",
            "Epoch 36 Loss 2.6288933753967285\n",
            "Epoch 36 Validation Loss 3.3766825199127197\n",
            "Time taken for 1 epoch 1186.2391159534454 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.9085745811462402\n",
            "Epoch 37 Batch 400 Loss 2.2579143047332764\n",
            "Epoch 37 Batch 800 Loss 2.9517595767974854\n",
            "Epoch 37 Batch 1200 Loss 2.4083545207977295\n",
            "Epoch 37 Batch 1600 Loss 2.7253079414367676\n",
            "Epoch 37 Loss 2.586362838745117\n",
            "Epoch 37 Validation Loss 3.3592495918273926\n",
            "Time taken for 1 epoch 1186.0309455394745 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.872626304626465\n",
            "Epoch 38 Batch 400 Loss 2.292529344558716\n",
            "Epoch 38 Batch 800 Loss 2.8788647651672363\n",
            "Epoch 38 Batch 1200 Loss 2.4006381034851074\n",
            "Epoch 38 Batch 1600 Loss 2.698836326599121\n",
            "Epoch 38 Loss 2.590353012084961\n",
            "Epoch 38 Validation Loss 3.3483848571777344\n",
            "Time taken for 1 epoch 1185.3590922355652 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 2.8492953777313232\n",
            "Epoch 39 Batch 400 Loss 2.2168776988983154\n",
            "Epoch 39 Batch 800 Loss 2.8068199157714844\n",
            "Epoch 39 Batch 1200 Loss 2.363072156906128\n",
            "Epoch 39 Batch 1600 Loss 2.6676361560821533\n",
            "Epoch 39 Loss 2.526381731033325\n",
            "Epoch 39 Validation Loss 3.3400824069976807\n",
            "Time taken for 1 epoch 1185.758291721344 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 2.816106081008911\n",
            "Epoch 40 Batch 400 Loss 2.1855461597442627\n",
            "Epoch 40 Batch 800 Loss 2.7731761932373047\n",
            "Epoch 40 Batch 1200 Loss 2.3386194705963135\n",
            "Epoch 40 Batch 1600 Loss 2.6408698558807373\n",
            "Epoch 40 Loss 2.503774404525757\n",
            "Epoch 40 Validation Loss 3.3392794132232666\n",
            "Time taken for 1 epoch 1185.8981778621674 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6izlBCCiYjLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8462a117-db6e-4f2a-dd80-d7131f802b83"
      },
      "source": [
        "print(total_loss)\n",
        "print(val_total_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(5007.549, shape=(), dtype=float32)\n",
            "tf.Tensor(1709.711, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSmRIiHBXirb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9aa3dfa6-cbf3-466e-fcf1-6f2cf6ef949f"
      },
      "source": [
        "epochs = range(0,EPOCHS)\n",
        "plt.plot(epochs, train_losses, 'g', label='Training loss')\n",
        "plt.plot(epochs, eval_losses, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gI8_gCNJ_tQ"
      },
      "source": [
        "# Epoch 1 Loss 1.283766269683838\n",
        "def evaluate_sentence(sentence):\n",
        "    sentence = data.preprocess(sentence)\n",
        "    inputs = data.tokenizer.texts_to_sequences([sentence])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                          maxlen=max_length_articles,\n",
        "                                                          padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    inference_batch_size = inputs.shape[0]\n",
        "    encoder.trainable = False\n",
        "    decoder.trainable = False\n",
        "    enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units)), tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "    decoded_seq = np.zeros((1,max_length_summaries))\n",
        "    decoded_seq[0,0]=word_index['<start>']\n",
        "    li_dec = decoded_seq\n",
        "    decoded_seq_word = '<start>'\n",
        "\n",
        "    li=[]\n",
        "    len_pred_summary = max_length_summaries - 2\n",
        "\n",
        "    dec_h = enc_h\n",
        "    dec_c = enc_c\n",
        "    dec_emb = decoder.embedding(decoded_seq)\n",
        "    ans_arr = []\n",
        "    cov = tf.zeros([1, max_length_articles], tf.float32)\n",
        "    for t in range(max_length_summaries-1):\n",
        "      decoder_initial_state = decoder.initialize_hidden_state(1, dec_h, dec_c)\n",
        "      input_t = dec_emb[:, t, :] \n",
        "      vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(input_t, decoder_initial_state, cov, enc_out, inp)\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "      ans_arr.append(np.argmax(vocab_dist, axis = 1))\n",
        "    \n",
        "    encoder.trainable = True\n",
        "    decoder.trainable = True\n",
        "    return ans_arr\n",
        "\n",
        "def summarize(sentence):\n",
        "  result = evaluate_sentence(sentence)\n",
        "  result = data.tokenizer.sequences_to_texts(result)\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(\" \".join(result)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZgTmt3iQIZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f05e3b-6fe1-465d-e02f-b0e1a32a13fc"
      },
      "source": [
        "test_sentence = \"There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahino’s nanny. Fletcher’s unveiling as the deadline day signing from Manchester United was almost eclipsed by the twenty-one-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahino’s senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford.\"\n",
        "summarize(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahino’s nanny. Fletcher’s unveiling as the deadline day signing from Manchester United was almost eclipsed by the twenty-one-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahino’s senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford.\n",
            "Predicted translation: prongs veendam <OOV> stepped garbine mcmillian millaa talalmusa erzurum dangerousness isinbayeva fnb varun walsingham virgo pasteurized azawad famers shirvington shirvington rules rules rules shirvington fulmer rules nautica rules hollander shirvington haith shirvington shirvington riske riske hollander nautica nautica nautica hollander hollander tachycardia streetwear hollander azawad eidur shirvington shirvington hollander hollander misguided misguided fadlallah okaka crennel crennel cre lesbians nautica sutay tunnicliffe malted danby standstill standstill perkin perkin jamaat canfield canfield canfield fadlallah briny hisar canfield hollander lesbians lesbians misfortune biosphere midori hattie hattie mek mek mek chats squared chats chats expansive przewalski przewalski przewalski murai przewalski przewalski suski suski suski suski klotz lloris macgillivray macgillivray macgillivray kampf clashes reclaim strawser strawser strawser coatings coatings flavour strawser bangle paparic milk savyon savyon milk lain elsey elsey elsey untouched\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQGJGfQ5ANd2"
      },
      "source": [
        "# saving weights\n",
        "!cp \"/content/training_checkpoints/checkpoint\" \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights\"\n",
        "!cp \"/content/training_checkpoints/ckpt-13.data-00000-of-00001\" \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights\"\n",
        "!cp \"/content/training_checkpoints/ckpt-13.index\" \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-oOPZelHcBk",
        "outputId": "957bfa4b-c332-4bb0-a47f-2aabeab1dda0"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/checkpoint\" \"/content/training_checkpoints/\"\n",
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-5.data-00000-of-00001\" \"/content/training_checkpoints/\"\n",
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-5.index\" \"/content/training_checkpoints/\"\n",
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1e0c19e9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1IyuDbx5qXQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}