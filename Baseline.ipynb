{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Baseline(from scratch).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a87c6302b0f4e5b836c7766949be6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1202990c0f04a948044998304308f59",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc40329e189c48bf94188973ddbbba8a",
              "IPY_MODEL_4a77c8c587984f60842bc048cc7afaf4"
            ]
          }
        },
        "f1202990c0f04a948044998304308f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc40329e189c48bf94188973ddbbba8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8bb62c8e9a0a4a1a858d352e085541d6",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5d2a7721db448249511c720fbfe6134"
          }
        },
        "4a77c8c587984f60842bc048cc7afaf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a11cea19f34459aab7ffc786e691150",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [01:22&lt;00:00, 16.59s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95d47a06bcc8457992e7f66dbfdb340f"
          }
        },
        "8bb62c8e9a0a4a1a858d352e085541d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5d2a7721db448249511c720fbfe6134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a11cea19f34459aab7ffc786e691150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95d47a06bcc8457992e7f66dbfdb340f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b803e43a4c2a47efa853c6645d402232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c822c450de55475f85826d94d9a7d055",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d46c09162584401ae5e9a80bb7a1b95",
              "IPY_MODEL_561d5bc035834f9186584d55bb6e703e"
            ]
          }
        },
        "c822c450de55475f85826d94d9a7d055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d46c09162584401ae5e9a80bb7a1b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea7d383eb1f042708bf51ebfe6b6c6c5",
            "_dom_classes": [],
            "description": "Dl Size...: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b16c0a8ed8de4c96a671699c5e58687a"
          }
        },
        "561d5bc035834f9186584d55bb6e703e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80a0326b311a41439b4f5dbea5f8a203",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/? [01:22&lt;00:00,  6.72 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8d6ea0b789c44ebb83e5cfdb941b84d"
          }
        },
        "ea7d383eb1f042708bf51ebfe6b6c6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b16c0a8ed8de4c96a671699c5e58687a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80a0326b311a41439b4f5dbea5f8a203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8d6ea0b789c44ebb83e5cfdb941b84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2385adc6b992444b9a6e05f4c68755f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_400e7c289aeb4d85b5d915c7e284f1f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71cbcfe6315742e2b9f6875238043483",
              "IPY_MODEL_6aec166efef64762ba1e41cab3a9aca6"
            ]
          }
        },
        "400e7c289aeb4d85b5d915c7e284f1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71cbcfe6315742e2b9f6875238043483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86f0c62516824b0990873f0caf5fb99f",
            "_dom_classes": [],
            "description": "Extraction completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d9646b414824b96ba8ce3b5ae8d230b"
          }
        },
        "6aec166efef64762ba1e41cab3a9aca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7916cccb0a0431691b9b55ad8b02f7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [01:22&lt;00:00, 41.44s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_461c02b886384336b519b5a8736964cf"
          }
        },
        "86f0c62516824b0990873f0caf5fb99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d9646b414824b96ba8ce3b5ae8d230b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7916cccb0a0431691b9b55ad8b02f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "461c02b886384336b519b5a8736964cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8ae82b954c74472ba69002ad8431ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4193f1f6f039458795e23cf40d47d65c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bcffb0367da4e2a9d95b6bbe595150b",
              "IPY_MODEL_950a8a5172ba4778b5715e5041b94431"
            ]
          }
        },
        "4193f1f6f039458795e23cf40d47d65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bcffb0367da4e2a9d95b6bbe595150b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8f1e14d50bf43bca11d8b84ebf38a09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f92535ca5bbe48acbf888f69aa79f7bb"
          }
        },
        "950a8a5172ba4778b5715e5041b94431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ecda295362ef471f9c3a0e4bfa22dfef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 287113/0 [03:05&lt;00:00, 1490.94 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc9f4dd29db244a186c213a44e6461db"
          }
        },
        "f8f1e14d50bf43bca11d8b84ebf38a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f92535ca5bbe48acbf888f69aa79f7bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecda295362ef471f9c3a0e4bfa22dfef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc9f4dd29db244a186c213a44e6461db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfa0b352253240728f3d77bebf786e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d35fce0d5a449ebb74c81dcb53dd1c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76d307f58e41410baff0b8dd1b865214",
              "IPY_MODEL_ba21041f22c245c68e5811ca1e16d6d7"
            ]
          }
        },
        "0d35fce0d5a449ebb74c81dcb53dd1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76d307f58e41410baff0b8dd1b865214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45930394ad224f3999929493925df2cd",
            "_dom_classes": [],
            "description": " 98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 287113,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 282640,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc0c8977822b4ce3b456d93aeed09352"
          }
        },
        "ba21041f22c245c68e5811ca1e16d6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aba5273776b241e58a75c2bab5cec0d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 282640/287113 [00:09&lt;00:00, 50252.30 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5c178da954a4c9caaddbc57740b9e5e"
          }
        },
        "45930394ad224f3999929493925df2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc0c8977822b4ce3b456d93aeed09352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aba5273776b241e58a75c2bab5cec0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5c178da954a4c9caaddbc57740b9e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c5de64e78b94caabb8cdaad44608a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b44aab6d52f4f08ab32418b076ebdba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce6e4a92d02f426e8c314e159df9e401",
              "IPY_MODEL_b727ae11d4cb4212a71edd482e38b08d"
            ]
          }
        },
        "5b44aab6d52f4f08ab32418b076ebdba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce6e4a92d02f426e8c314e159df9e401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_111a6e720e044806944d82c84bed0bcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa740c63be914c5e88d70b20cdd90284"
          }
        },
        "b727ae11d4cb4212a71edd482e38b08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e96cc60f32d4bdc80b6287158692aab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13368/0 [00:07&lt;00:00, 1703.64 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21dfec1aba8b47c7adc2add488a4e810"
          }
        },
        "111a6e720e044806944d82c84bed0bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa740c63be914c5e88d70b20cdd90284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e96cc60f32d4bdc80b6287158692aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21dfec1aba8b47c7adc2add488a4e810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7a0a59e4a3741c6bca6bf42c9d0f279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_248b17b38a664412ab39ce3bbdee49cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9dd8d502a7e4858991de2469e1e7e09",
              "IPY_MODEL_1b78df503f564f02930e0c75056138d7"
            ]
          }
        },
        "248b17b38a664412ab39ce3bbdee49cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9dd8d502a7e4858991de2469e1e7e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb92b31ea2c048e0b6a46efb8212ab7b",
            "_dom_classes": [],
            "description": " 66%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 13368,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea5329621d8b4740aa63a2baaa4e7bf6"
          }
        },
        "1b78df503f564f02930e0c75056138d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0ff240b625b74d99bcce7facad076123",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8766/13368 [00:00&lt;00:00, 87653.81 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50ea4e37c09f448f8d3b1cbadf521881"
          }
        },
        "eb92b31ea2c048e0b6a46efb8212ab7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea5329621d8b4740aa63a2baaa4e7bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ff240b625b74d99bcce7facad076123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50ea4e37c09f448f8d3b1cbadf521881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5867aed108624756b45620931fe5cb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50057c8c497d485fbce4d421aa947b3f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64c5b42c7b524d33b887ef21b790cbd9",
              "IPY_MODEL_fd529d64f47e430e9b773c3144b5f14a"
            ]
          }
        },
        "50057c8c497d485fbce4d421aa947b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64c5b42c7b524d33b887ef21b790cbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25679de6478243cbbc8eafecc05fa66e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_171a5b045317427ab1ae83d75023aa2c"
          }
        },
        "fd529d64f47e430e9b773c3144b5f14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69d63cbbfff0473cb742d2582c27d366",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11490/0 [00:06&lt;00:00, 1679.61 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c29edd92ae7748eb8a13f287595c6eeb"
          }
        },
        "25679de6478243cbbc8eafecc05fa66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "171a5b045317427ab1ae83d75023aa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69d63cbbfff0473cb742d2582c27d366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c29edd92ae7748eb8a13f287595c6eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33989e37f51647aca8be744bee847273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d34bb718042a4a7d92c289cbea20e4f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08d8135d061a462ab368c125caae4f2a",
              "IPY_MODEL_e86ee84626474c00a08aa2b7b1345842"
            ]
          }
        },
        "d34bb718042a4a7d92c289cbea20e4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08d8135d061a462ab368c125caae4f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e0bc94d328e47c6ae0ffad49d1d34ea",
            "_dom_classes": [],
            "description": " 81%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 11490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9322,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8623b03398a54de58beaeb3dbe0446e8"
          }
        },
        "e86ee84626474c00a08aa2b7b1345842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8dec9eb1acd49518c46bef8e003a42e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9322/11490 [00:03&lt;00:00, 93219.64 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c364cd217a9a461ba4abe59d6f722e32"
          }
        },
        "0e0bc94d328e47c6ae0ffad49d1d34ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8623b03398a54de58beaeb3dbe0446e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8dec9eb1acd49518c46bef8e003a42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c364cd217a9a461ba4abe59d6f722e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandeshRangreji/Pointer-Generator-Networks/blob/main/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFe8Tuv1j1Vf",
        "outputId": "047493ec-0c27-4a3a-d0a7-2b54f25689c2"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 21 04:20:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB66MTa6j-zW",
        "outputId": "8c0435d4-2ee7-422e-8aaa-b7182efba9eb"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIOujJRQFsjR",
        "outputId": "46ae90a8-77b5-492e-a8e5-54487b964707"
      },
      "source": [
        "pip install tensorflow-addons"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 26.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 25.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 17.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 19.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 14.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 14.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ROq-CnaCxiy",
        "outputId": "62f6be0d-b6d3-4bcb-ecec-de2f9f85fd1a"
      },
      "source": [
        "pip install --upgrade tensorflow-lattice"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-lattice\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/35/3cb42ede037885c24010ad69a128318f88b159a45e7508d2b82666a1f193/tensorflow_lattice-2.0.8-py2.py3-none-any.whl (225kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 27.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 26.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 51kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 61kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 71kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 81kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 102kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 112kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 122kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 133kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 143kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 153kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 163kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 174kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 184kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 194kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 204kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 215kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: sklearn in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.0)\n",
            "Collecting dm-sonnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/28/9185afffefb655ef1a29f4b84aa9f656826408ca2d1b9ffeba81fbfd40ec/dm_sonnet-2.0.0-py3-none-any.whl (254kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 26.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow-lattice) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow-lattice) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->tensorflow-lattice) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: dm-tree>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (0.1.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (0.8.9)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->tensorflow-lattice) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->tensorflow-lattice) (1.4.1)\n",
            "Installing collected packages: dm-sonnet, tensorflow-lattice\n",
            "Successfully installed dm-sonnet-2.0.0 tensorflow-lattice-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVJ2Zjl2e13P"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_lattice as tfl\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GypFb5xFgL-S",
        "outputId": "f087e0b4-f4fc-4265-b8a1-2f4217b9bf4d"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd8EHJ67go_u",
        "outputId": "7f0c90b9-9d00-44f9-fbca-4c0b6d08b23c"
      },
      "source": [
        "# unzips Glove word embeddings\n",
        "!unrar x \"/content/drive/MyDrive/Pointer Generator Networks/glove.6B.300d.rar\" -d \"/content/PGN/data/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/Pointer Generator Networks/glove.6B.300d.rar\n",
            "\n",
            "Creating    /content/PGN                                              OK\n",
            "Creating    /content/PGN/data                                         OK\n",
            "Extracting  /content/PGN/data/glove.6B.300d.txt                          \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5gXu4Z1lEOz"
      },
      "source": [
        "# class to handle data loading, splitting, preprocessing, tokenization\n",
        "class Data:\n",
        "\n",
        "  def __init__(self, vocab_size, oov_token):\n",
        "    # dictionary for contractions\n",
        "    self.tokenizer = Tokenizer(num_words = vocab_size, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token=oov_token)\n",
        "    self.contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "  # function to perform contractions\n",
        "  def split_contractions(self, sentence):\n",
        "    # parameters:\n",
        "    # sentence: article/summary (string)\n",
        "    # making a list of words from the article/summary\n",
        "    # return: article/summary after contractions (string)\n",
        "    li_sentence = sentence.split(' ')\n",
        "    # iterating through each word and replacing the contracted word if it is present in contraction dictionary\n",
        "    for i in range(len(li_sentence)):\n",
        "      li_sentence[i] = self.contractions.get(li_sentence[i], li_sentence[i])\n",
        "    # combining the list to form a string again\n",
        "    sentence = ' '.join(li_sentence)\n",
        "    return sentence\n",
        "\n",
        "  # function to handle preprocessing of articles and summaries\n",
        "  def preprocess(self, sentence):\n",
        "    # parameters:\n",
        "    # sentence: article or summary to be processed\n",
        "    # returns:\n",
        "    # sentence: cleaned article/summary\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    sentence = self.split_contractions(sentence)\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = \"<sos> \" + sentence\n",
        "    sentence = sentence.replace(\" . \", \" <sos> <eos> \")\n",
        "    sentence = sentence[:len(sentence) - 7]\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    # removing trailing spaces\n",
        "    sentence = sentence.lower().strip()\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence  \n",
        "  \n",
        "  # splitting data into articles and summaries for training and testing\n",
        "  def split_data(self, dataset):\n",
        "    # parameters:\n",
        "    # dataset : tfds of cnn_dailymail dataset (bytes)\n",
        "    # returns:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (string)\n",
        "    train_articles = []\n",
        "    train_summaries = []\n",
        "    eval_articles = []\n",
        "    eval_summaries = []\n",
        "    # iterating through train dataset and storing articles and summaries seperately\n",
        "    for text in tfds.as_numpy(dataset['train']):\n",
        "      # decoding from bytes to string\n",
        "      article = self.preprocess(text['article'].decode(\"utf-8\"))\n",
        "      summaries = self.preprocess(text['highlights'].decode(\"utf-8\"))\n",
        "      train_articles.append(article)\n",
        "      train_summaries.append(summaries)\n",
        "\n",
        "    # iterating through validation dataset and storing articles and summaries seperately\n",
        "    for text in tfds.as_numpy(dataset['validation']):\n",
        "      # decoding from bytes to string\n",
        "      article = self.preprocess(text['article'].decode(\"utf-8\"))\n",
        "      summaries = self.preprocess(text['highlights'].decode(\"utf-8\"))\n",
        "      eval_articles.append(article)\n",
        "      eval_summaries.append(summaries)\n",
        "    return train_articles, train_summaries, eval_articles, eval_summaries\n",
        "\n",
        "  # function to tokenize data\n",
        "  def tokenize(self, train_articles, train_summaries, eval_articles, eval_summaries, vocab_size , embedding_dim, max_length_articles, max_length_summaries, truncating_type, padding_type, oov_token):\n",
        "    # parameters:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (string)\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimensions of word embeddings\n",
        "    # max_lengths_articles: number of words in the longest article\n",
        "    # max_lengths_summaries: number of words in the longest summary\n",
        "    # truncating_type: pre/post truncatation\n",
        "    # padding_type: pro/post padding\n",
        "    # oov_token: specifies what oov_token should be used\n",
        "    # return:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (sequences)\n",
        "    # initialize tokenizer\n",
        "    # fit tokenizer on training input (vocab)\n",
        "    self.tokenizer.fit_on_texts(train_articles)\n",
        "    # get word index from tokenizer\n",
        "    word_index = self.tokenizer.word_index\n",
        "    # tokenize articles for training \n",
        "    train_articles = self.tokenizer.texts_to_sequences(train_articles)\n",
        "    train_articles = pad_sequences(train_articles ,maxlen=max_length_articles, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize summaries for training \n",
        "    eval_articles = self.tokenizer.texts_to_sequences(eval_articles)\n",
        "    eval_articles = pad_sequences(eval_articles, maxlen=max_length_articles, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize articles for eval \n",
        "    train_summaries = self.tokenizer.texts_to_sequences(train_summaries)\n",
        "    train_summaries = pad_sequences(train_summaries ,maxlen=max_length_summaries, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize summaries for eval \n",
        "    eval_summaries = self.tokenizer.texts_to_sequences(eval_summaries)\n",
        "    eval_summaries = pad_sequences(eval_summaries, maxlen=max_length_summaries, padding=padding_type, truncating=truncating_type)\n",
        "    return train_articles, train_summaries, eval_articles, eval_summaries, word_index\n",
        "\n",
        "  # function to get a dictionery which is the reverse of the word_index\n",
        "  def get_reverse_word_index(self, word_index):\n",
        "    # parameters:\n",
        "    # word_index : { word : id }\n",
        "    # returns\n",
        "    # reverse_word_index : { id : word }\n",
        "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "    return reverse_word_index\n",
        "\n",
        "  # get important metrics of the dataset that is needed to build a model\n",
        "  def get_data_metrics(self):\n",
        "    # return:\n",
        "    # average length of articles, average length of summaries, length of longest article, length of longest summary\n",
        "    # loading dataset\n",
        "    ds = tfds.load(\"cnn_dailymail\")\n",
        "    # decoding and splitting dataset into train and eval articles and summaries\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries = self.split_data(ds)\n",
        "    train_article_sum = 0\n",
        "    max_article_len = 0\n",
        "    max_summary_len = 0\n",
        "    train_summaries_sum = 0\n",
        "    # iterating through dataset to count total number of words\n",
        "    for i in range(len(train_articles)):\n",
        "      # current article and summary length (no. of words)\n",
        "      article_len = len(train_articles[i].split())\n",
        "      summary_len = len(train_summaries[i].split())\n",
        "      # finding length of article with most number of words\n",
        "      if(article_len>max_article_len):\n",
        "        max_article_len = article_len\n",
        "      # finding length of summary with most number of words\n",
        "      if(summary_len>max_summary_len):\n",
        "        max_summary_len = summary_len\n",
        "      # calculating total number of words accross all articles and summary to calculate average\n",
        "      train_article_sum = train_article_sum + article_len\n",
        "      train_summaries_sum = train_summaries_sum + summary_len\n",
        "    return train_article_sum/len(train_articles), train_summaries_sum/len(train_summaries), max_article_len, max_summary_len \n",
        "\n",
        "  # function to load pretrained word embeddings and prepare them for embedding layer\n",
        "  def get_word_embeddings(self, word_index, vocab_size, embedding_dim):\n",
        "    # parameters:\n",
        "    # word_index: { word:id }\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimension of word embeddings\n",
        "    embeddings_index = {}\n",
        "    # opening and reading word embeddings from file\n",
        "    with open('/content/PGN/data/glove.6B.' + str(embedding_dim) + 'd.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "\n",
        "    # converting word embeddings to matrix (weights for embedding layer) using word_index\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None and i<=vocab_size:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "    return embeddings_index, embeddings_matrix\n",
        "\n",
        "  # function to convert list of articles and summaries to iterable, batched datasets\n",
        "  def batch_datasets(self, train_articles, train_summaries, eval_articles, eval_summaries, BATCH_SIZE):\n",
        "    # parameters:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (sequences)\n",
        "    # BATCH_SIZE: size of one batch in the dataset\n",
        "    # return:\n",
        "    # train_dataset, val_dataset: dataset objects for training and evaluation, batched according to BATCH_SIZE\n",
        "    # making a dataset object from the train articles and summaries\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_articles, train_summaries))\n",
        "    # batching training dataset\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    # making a dataset object from the evaluation articles and summaries\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((eval_articles, eval_summaries))\n",
        "    # batching evaluation dataset\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "  def __call__(self, num_training_examples = 2048, vocab_size = 25000, embedding_dim = 200, max_length_articles = 2880, max_length_summaries = 1344, truncating_type='post', padding_type='post', oov_token='<OOV>', BATCH_SIZE=64):\n",
        "    # parameters:\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimensions of word embeddings\n",
        "    # max_lengths_articles: number of words in the longest article\n",
        "    # max_lengths_summaries: number of words in the longest summary\n",
        "    # truncating_type: pre/post truncatation\n",
        "    # padding_type: pro/post padding\n",
        "    # oov_token: specifies what oov_token should be used\n",
        "    # returns:\n",
        "    # train_dataset, val_dataset: dataset objects for training and evaluation, batched according to BATCH_SIZE\n",
        "    # word_index : { word : id }\n",
        "    # reverse_word_index : { id : word }\n",
        "\n",
        "    # loading data in bytes from tfds\n",
        "    ds=tfds.load(\"cnn_dailymail\", shuffle_files = False)\n",
        "    # splitting data into train and test sets of articles and summaries\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries = self.split_data(ds)\n",
        "    # tokenizing data\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries, word_index = self.tokenize(\n",
        "        train_articles[:num_training_examples], \n",
        "        train_summaries[:num_training_examples], \n",
        "        eval_articles[:2048], \n",
        "        eval_summaries[:2048],\n",
        "        vocab_size , \n",
        "        embedding_dim, \n",
        "        max_length_articles, \n",
        "        max_length_summaries, \n",
        "        truncating_type, \n",
        "        padding_type, \n",
        "        oov_token)\n",
        "    # vocab_size = len(word_index)\n",
        "    # converting list of articles to train and evaluation datasets that are in batches\n",
        "    train_dataset, validation_dataset = self.batch_datasets(train_articles, train_summaries, eval_articles, eval_summaries, BATCH_SIZE)\n",
        "    return train_dataset, validation_dataset, word_index, self.get_reverse_word_index(word_index)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447,
          "referenced_widgets": [
            "2a87c6302b0f4e5b836c7766949be6cd",
            "f1202990c0f04a948044998304308f59",
            "dc40329e189c48bf94188973ddbbba8a",
            "4a77c8c587984f60842bc048cc7afaf4",
            "8bb62c8e9a0a4a1a858d352e085541d6",
            "a5d2a7721db448249511c720fbfe6134",
            "8a11cea19f34459aab7ffc786e691150",
            "95d47a06bcc8457992e7f66dbfdb340f",
            "b803e43a4c2a47efa853c6645d402232",
            "c822c450de55475f85826d94d9a7d055",
            "8d46c09162584401ae5e9a80bb7a1b95",
            "561d5bc035834f9186584d55bb6e703e",
            "ea7d383eb1f042708bf51ebfe6b6c6c5",
            "b16c0a8ed8de4c96a671699c5e58687a",
            "80a0326b311a41439b4f5dbea5f8a203",
            "d8d6ea0b789c44ebb83e5cfdb941b84d",
            "2385adc6b992444b9a6e05f4c68755f1",
            "400e7c289aeb4d85b5d915c7e284f1f6",
            "71cbcfe6315742e2b9f6875238043483",
            "6aec166efef64762ba1e41cab3a9aca6",
            "86f0c62516824b0990873f0caf5fb99f",
            "2d9646b414824b96ba8ce3b5ae8d230b",
            "f7916cccb0a0431691b9b55ad8b02f7e",
            "461c02b886384336b519b5a8736964cf",
            "a8ae82b954c74472ba69002ad8431ebd",
            "4193f1f6f039458795e23cf40d47d65c",
            "0bcffb0367da4e2a9d95b6bbe595150b",
            "950a8a5172ba4778b5715e5041b94431",
            "f8f1e14d50bf43bca11d8b84ebf38a09",
            "f92535ca5bbe48acbf888f69aa79f7bb",
            "ecda295362ef471f9c3a0e4bfa22dfef",
            "dc9f4dd29db244a186c213a44e6461db",
            "dfa0b352253240728f3d77bebf786e36",
            "0d35fce0d5a449ebb74c81dcb53dd1c5",
            "76d307f58e41410baff0b8dd1b865214",
            "ba21041f22c245c68e5811ca1e16d6d7",
            "45930394ad224f3999929493925df2cd",
            "dc0c8977822b4ce3b456d93aeed09352",
            "aba5273776b241e58a75c2bab5cec0d2",
            "f5c178da954a4c9caaddbc57740b9e5e",
            "5c5de64e78b94caabb8cdaad44608a6e",
            "5b44aab6d52f4f08ab32418b076ebdba",
            "ce6e4a92d02f426e8c314e159df9e401",
            "b727ae11d4cb4212a71edd482e38b08d",
            "111a6e720e044806944d82c84bed0bcf",
            "aa740c63be914c5e88d70b20cdd90284",
            "6e96cc60f32d4bdc80b6287158692aab",
            "21dfec1aba8b47c7adc2add488a4e810",
            "e7a0a59e4a3741c6bca6bf42c9d0f279",
            "248b17b38a664412ab39ce3bbdee49cd",
            "d9dd8d502a7e4858991de2469e1e7e09",
            "1b78df503f564f02930e0c75056138d7",
            "eb92b31ea2c048e0b6a46efb8212ab7b",
            "ea5329621d8b4740aa63a2baaa4e7bf6",
            "0ff240b625b74d99bcce7facad076123",
            "50ea4e37c09f448f8d3b1cbadf521881",
            "5867aed108624756b45620931fe5cb40",
            "50057c8c497d485fbce4d421aa947b3f",
            "64c5b42c7b524d33b887ef21b790cbd9",
            "fd529d64f47e430e9b773c3144b5f14a",
            "25679de6478243cbbc8eafecc05fa66e",
            "171a5b045317427ab1ae83d75023aa2c",
            "69d63cbbfff0473cb742d2582c27d366",
            "c29edd92ae7748eb8a13f287595c6eeb",
            "33989e37f51647aca8be744bee847273",
            "d34bb718042a4a7d92c289cbea20e4f4",
            "08d8135d061a462ab368c125caae4f2a",
            "e86ee84626474c00a08aa2b7b1345842",
            "0e0bc94d328e47c6ae0ffad49d1d34ea",
            "8623b03398a54de58beaeb3dbe0446e8",
            "c8dec9eb1acd49518c46bef8e003a42e",
            "c364cd217a9a461ba4abe59d6f722e32"
          ]
        },
        "id": "3OehanrRoj_u",
        "outputId": "616e5e61-26b1-43f9-e9bd-44b163b230bd"
      },
      "source": [
        "vocab_size = 50000\n",
        "num_examples = 32768\n",
        "# num_examples = 2048\n",
        "embedding_dim = 300\n",
        "max_length_articles = 512\n",
        "max_length_summaries = 128\n",
        "truncating_type ='post'\n",
        "padding_type ='post'\n",
        "oov_token = \"<OOV>\"\n",
        "BATCH_SIZE = 16\n",
        "data = Data(vocab_size, oov_token)\n",
        "# load, split, batch data\n",
        "train_dataset, val_dataset, word_index, reverse_word_index = data(\n",
        "        num_examples,\n",
        "        vocab_size, \n",
        "        embedding_dim, \n",
        "        max_length_articles, \n",
        "        max_length_summaries, \n",
        "        truncating_type, \n",
        "        padding_type, \n",
        "        oov_token,\n",
        "        BATCH_SIZE)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cnn_dailymail/plain_text/3.0.0 (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a87c6302b0f4e5b836c7766949be6cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b803e43a4c2a47efa853c6645d402232",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2385adc6b992444b9a6e05f4c68755f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8ae82b954c74472ba69002ad8431ebd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0.incompleteO6MTDJ/cnn_dailymail-train.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfa0b352253240728f3d77bebf786e36",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=287113.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c5de64e78b94caabb8cdaad44608a6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0.incompleteO6MTDJ/cnn_dailymail-validation.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7a0a59e4a3741c6bca6bf42c9d0f279",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=13368.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5867aed108624756b45620931fe5cb40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0.incompleteO6MTDJ/cnn_dailymail-test.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33989e37f51647aca8be744bee847273",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11490.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n",
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset cnn_dailymail downloaded and prepared to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBMPgFoEqxhD"
      },
      "source": [
        "# get word embeddings in the form of a matrix\n",
        "embeddings_index, embeddings_matrix = data.get_word_embeddings(word_index, vocab_size, embedding_dim)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzIxZw99RuAy",
        "outputId": "95561fc4-560f-4148-849a-699b814db0c6"
      },
      "source": [
        "embeddings_matrix.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3nKYCnZ7Tdw",
        "outputId": "c4ac8a27-74fb-4d40-d431-273669f14e82"
      },
      "source": [
        "# sample data from dataset\n",
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([16, 512]), TensorShape([16, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJcHSb8Apscl"
      },
      "source": [
        "# class for Encoder model\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, embeddings_matrix, hidden_dim):\n",
        "    # parameters:\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dims: dimension of word embeddings\n",
        "    # enc_units: number of LSTM units in the encoder\n",
        "    # batch_sz: batch size of data\n",
        "    # embedding_matrix: word embeddings in the form of a matrix\n",
        "    super(Encoder, self).__init__()\n",
        "    # initializing model layers and some parameters of those layers\n",
        "    self.batch_sz = batch_sz\n",
        "    self.l1_enc_units = enc_units\n",
        "    self.l2_enc_units = enc_units//2\n",
        "    # self.l3_enc_units = enc_units//4\n",
        "    # initializing embedding layer with pretrained word embeddings\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length_articles, weights=[embeddings_matrix], trainable=False)\n",
        "\n",
        "    ##________ LSTM layer in Encoder ------- ##\n",
        "    self.lstm_layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l1_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    self.lstm_layer_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l2_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    # self.lstm_layer_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l3_enc_units,\n",
        "    #                                return_sequences=True,\n",
        "    #                                return_state=True,\n",
        "    #                                recurrent_initializer='glorot_uniform'))\n",
        "    self.reduce_h = tf.keras.layers.Dense(units = hidden_dim, use_bias=True)\n",
        "    self.reduce_c = tf.keras.layers.Dense(units = hidden_dim, use_bias=True)\n",
        "\n",
        "\n",
        "  # build encoder model\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output_1, forward_h1, forward_c1, backward_h1, backward_c1 = self.lstm_layer_1(x, initial_state = hidden )\n",
        "    output_2, forward_h2, forward_c2, backward_h2, backward_c2 = self.lstm_layer_2(output_1)\n",
        "    # output_3, forward_h3, forward_c3, backward_h3, backward_c3 = self.lstm_layer_3(output_2)\n",
        "    # h = tf.concat([forward_h1, backward_h1], axis=-1)\n",
        "    # c = tf.concat([forward_c1, backward_c1], axis=-1)\n",
        "    h = tf.concat([forward_h2, backward_h2], axis=-1)\n",
        "    c = tf.concat([forward_c2, backward_c2], axis=-1)\n",
        "    # h = tf.concat([forward_h3, backward_h3], axis=-1)\n",
        "    # c = tf.concat([forward_c3, backward_c3], axis=-1)\n",
        "    final_h = tf.keras.activations.relu(self.reduce_h(h))\n",
        "    final_c = tf.keras.activations.relu(self.reduce_c(c))\n",
        "    return output_1, final_h, final_c\n",
        "\n",
        "  # initializing weights\n",
        "  def initialize_hidden_state(self):\n",
        "    return [tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units))]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE2MZNq7px80",
        "outputId": "b3333d0c-d3f3-4476-a23a-dacf202a517c"
      },
      "source": [
        "## Test Encoder Stack\n",
        "\n",
        "units = 256\n",
        "# dec_units = units//2\n",
        "dec_units = units\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE, embeddings_matrix, dec_units)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder h vector shape: (batch size, units) {}'.format(sample_h.shape))\n",
        "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (16, 512, 512)\n",
            "Encoder h vector shape: (batch size, units) (16, 256)\n",
            "Encoder c vector shape: (batch size, units) (16, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0YP1g30zPV2"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.v = tf.keras.layers.Dense(units = 1, use_bias=False)                       # v\n",
        "    self.enc_proj = tf.keras.layers.Dense(units = hidden_dim*2, use_bias=False)      # W_h\n",
        "    self.dec_proj = tf.keras.layers.Dense(units = hidden_dim*2, use_bias=True)        # W_s, b_attn\n",
        "    self.w_c = tf.keras.layers.Dense(units = hidden_dim*2 , use_bias=False)                     # W_c\n",
        "\n",
        "  def __call__(self, dec_input, coverage, enc_hidden):\n",
        "    enc_feature = self.enc_proj(enc_hidden)         # [B x L x 2H]\n",
        "    dec_feature = self.dec_proj(dec_input)          # [B x 2H]\n",
        "    dec_feature = tf.expand_dims(dec_feature, 1)    # [B x 1 x 2H]\n",
        "    # print(enc_feature.shape)\n",
        "    # print(dec_feature.shape)\n",
        "    scores = enc_feature + dec_feature              # [B x L x 2H]\n",
        "\n",
        "    coverage = tf.expand_dims(coverage, -1)      # [B x L x 1]\n",
        "    cov_feature = self.w_c(coverage)            # [B x L x 2H]\n",
        "    scores = scores + cov_feature\n",
        "\n",
        "    scores = tf.keras.activations.tanh(scores)                     # [B x L x 2H]\n",
        "    scores = self.v(scores)                         # [B x L x 1]\n",
        "    scores = tf.squeeze(scores, -1)                     # [B x L]\n",
        "    attn_dist = tf.keras.activations.softmax(scores, axis = -1)               # [B x L]\n",
        "    return attn_dist"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMfuORfuD4dz",
        "outputId": "4dd23a4a-c143-4889-9cfe-3e71cbdab2fa"
      },
      "source": [
        "attention = Attention(dec_units)\n",
        "coverage = np.random.randn(BATCH_SIZE, max_length_articles)\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, dec_units))\n",
        "attn_dist = attention(sample_x, coverage, sample_output)\n",
        "print(attn_dist.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvwhGVczp85q"
      },
      "source": [
        "class PointerGenerator(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(PointerGenerator, self).__init__()\n",
        "    self.w_h = tf.keras.layers.Dense(units = 1, use_bias=False) \n",
        "    self.w_s = tf.keras.layers.Dense(units = 1, use_bias=False) \n",
        "    self.w_x = tf.keras.layers.Dense(units = 1, use_bias=True) \n",
        "\n",
        "  def call(self, context_vec, dec_input, outputs, vocab_dist, attn_dist):\n",
        "    # Eq. (8) - Compute generation probability p_gen\n",
        "    context_feat = self.w_h(context_vec)                    # [B x 1]\n",
        "    decoder_feat = self.w_s(outputs)                              # [B x 1]\n",
        "    input_feat = self.w_x(dec_input)                          # [B x 1]\n",
        "    \n",
        "    gen_feat = context_feat + decoder_feat + input_feat\n",
        "    p_gen = tf.keras.activations.sigmoid(gen_feat)                            # [B x 1]\n",
        "\n",
        "    # Eq. (9) - Compute prob dist'n over extended vocabulary\n",
        "    vocab_dist = p_gen * vocab_dist                         # [B x V]\n",
        "    weighted_attn_dist = (1.0 - p_gen) * attn_dist          # [B x L]\n",
        "    return weighted_attn_dist, vocab_dist"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z64oJe-zqBLQ"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    # Embedding Layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    # Define the fundamental cell for decoder recurrent structure\n",
        "    self.rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
        "    # Define the attention layer\n",
        "    self.attention = Attention(self.dec_units)\n",
        "    # Define the Pointer Generator \n",
        "    # self.pointerGen = PointerGenerator()\n",
        "    # Fully Connected layers\n",
        "    self.v = tf.keras.layers.Dense(units = dec_units, use_bias=True)   # V, b\n",
        "    self.v_out = tf.keras.layers.Dense(units = vocab_size, use_bias=True)   # V', b'\n",
        "    \n",
        "  def initialize_hidden_state(self, batch_sz, sample_h, sample_c):\n",
        "    return [sample_h, sample_c]\n",
        "\n",
        "  def embedding(self, input):\n",
        "    return self.embedding(input)\n",
        "\n",
        "  def __call__(self, x, hidden, cov, enc_output, indices):  \n",
        "    # print(\"In decoder\")\n",
        "    hidden, cell = self.rnn_cell(x, hidden)\n",
        "    attn_dist = self.attention(hidden, cov, enc_output)\n",
        "    # The context vector is used later to compute generation probability\n",
        "    context_vec = tf.linalg.matmul(tf.expand_dims(attn_dist, 1), enc_output)   # [B x 1 x 2H]\n",
        "    context_vec = tf.math.reduce_sum(context_vec, axis = 1)                    # [B x 2H] \n",
        "    # Eq. (4)\n",
        "    output = self.v(tf.concat([hidden, context_vec], axis=-1))                # [B x 3H] -> [B x H]\n",
        "    output = self.v_out(output)                                                # [B x V]\n",
        "    vocab_dist = tf.keras.activations.softmax(output, axis=-1)                 # [B x V]\n",
        "    return vocab_dist, attn_dist, context_vec, output, cell[0], cell[1]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liyPdtoz7Wfl",
        "outputId": "f0d04b6d-7560-4971-d14d-99205e56c6dd"
      },
      "source": [
        "# Test decoder stack\n",
        "decoder = Decoder(vocab_size, embedding_dim, dec_units, BATCH_SIZE)\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, embedding_dim))\n",
        "hidden = decoder.initialize_hidden_state(BATCH_SIZE, sample_h, sample_c)\n",
        "cov_sample = np.zeros((BATCH_SIZE, max_length_articles))\n",
        "# sample_x = decoder.embedding(sample_x)\n",
        "vocab_dist, attn_dist, context_vec, sample_decoder_outputs, dec_h, dec_c = decoder(sample_x, hidden, cov_sample, sample_output, example_input_batch)\n",
        "\n",
        "# pointerGen = PointerGenerator()\n",
        "print(\"Vocab Distribution Shape: \", vocab_dist.shape)\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.shape)\n",
        "# print(\"LSTM Outputs Shape: \", sample_lstm_out.shape)\n",
        "print(\"Decoder hidden state Shape: \", dec_h.shape)\n",
        "print(\"Decoder cell state Shape: \", dec_c.shape)\n",
        "print(\"Attention Distribution Shape: \", attn_dist.shape)\n",
        "print(\"Context Vector Shape: \", context_vec.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Distribution Shape:  (16, 50000)\n",
            "Decoder Outputs Shape:  (16, 50000)\n",
            "Decoder hidden state Shape:  (16, 256)\n",
            "Decoder cell state Shape:  (16, 256)\n",
            "Attention Distribution Shape:  (16, 512)\n",
            "Context Vector Shape:  (16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7iZyk9kqLoP"
      },
      "source": [
        "def scatter_add(tensor, indices, updates):\n",
        "    original_tensor = tensor\n",
        "    # expand index value from vocab size\n",
        "    indices = tf.compat.v1.reshape(indices, shape=[-1, tf.shape(indices)[-1]])\n",
        "    indices_add = tf.compat.v1.expand_dims(tf.range(0, tf.shape(indices)[0], 1)*(tf.shape(tensor)[-1]), axis=-1)\n",
        "    indices += indices_add\n",
        "\n",
        "    # resize\n",
        "    tensor = tf.compat.v1.reshape(tensor, shape=[-1])\n",
        "    indices = tf.compat.v1.reshape(indices, shape=[-1, 1])\n",
        "    updates = tf.compat.v1.reshape(updates, shape=[-1])\n",
        "\n",
        "    # check_\n",
        "    \"\"\"\n",
        "    update = tensor.shape[indices.shape[-1]:]\n",
        "    res = indices.shape[:-1] + update\n",
        "    \"\"\"\n",
        "    # same Torch scatter_add_\n",
        "    scatter = tf.compat.v1.tensor_scatter_nd_add(tensor, indices, updates)\n",
        "    scatter = tf.compat.v1.reshape(scatter, shape=[tf.shape(original_tensor)[0], tf.shape(original_tensor)[1], -1])\n",
        "    return scatter"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4nDlcp7zVxL"
      },
      "source": [
        "initial_learning_rate = 0.001\n",
        "# step = tf.Variable(0, trainable=False)\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate,\n",
        "#     decay_steps=(num_examples//BATCH_SIZE) * 10,\n",
        "#     decay_rate=1.00,\n",
        "#     staircase=True)\n",
        "# wd = lambda: 1e-4 * lr_schedule(step)\n",
        "# optimizer = tfa.optimizers.AdamW(learning_rate=lr_schedule, clipnorm=1.0, weight_decay=wd)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  # real shape = (BATCH_SIZE, max_length_output)\n",
        "  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss\n",
        "\n",
        "def coverage_loss(attn_dist, coverage):\n",
        "  min_val = tf.math.minimum(attn_dist, coverage)   # [B x L x T]   \n",
        "  loss = tf.math.reduce_sum(min_val, axis=1)            # [B x T]\n",
        "  avg_loss = tf.math.reduce_sum(loss) / (BATCH_SIZE * max_length_summaries)\n",
        "  return avg_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJIeF-m65Wzv"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JgVFBL0NDJU"
      },
      "source": [
        "# saving weights\n",
        "def save_weights_in_drive(epoch):\n",
        "  if epoch!= 1:\n",
        "    os.remove(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-\" + str(epoch-1) + \".data-00000-of-00001\")\n",
        "    os.remove(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-\" + str(epoch-1) + \".index\")\n",
        "  shutil.copy2(\"/content/training_checkpoints/checkpoint\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  shutil.copy2(\"/content/training_checkpoints/ckpt-\" + str(epoch) + \".data-00000-of-00001\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  shutil.copy2(\"/content/training_checkpoints/ckpt-\" + str(epoch) + \".index\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXZblk5dqPp4"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden, cov):\n",
        "  loss = 0\n",
        "  cov_loss = 0\n",
        "  cov_weight = 1.0\n",
        "  # 3 lists\n",
        "  final_dists = []\n",
        "  attn_dists = []\n",
        "  coverages = []\n",
        "  with tf.GradientTape() as tape:\n",
        "    # print(\"Before encoder\")\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "    # print(\"Out of encoder\")\n",
        "    dec_inp = targ[ : , :-1 ]   # Ignore <end> token\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\n",
        "    # decoder_initial_state = decoder.initialize_hidden_state(BATCH_SIZE, enc_h, enc_c)\n",
        "    dec_h = enc_h\n",
        "    dec_c = enc_c\n",
        "    dec_emb = decoder.embedding(dec_inp)\n",
        "    cov = tf.zeros([BATCH_SIZE, max_length_articles], tf.float32)\n",
        "    # vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(dec_emb, decoder_initial_state, cov, enc_output, inp)\n",
        "    # cov = tf.cast(cov, dtype=tf.float32)\n",
        "    # cov = cov + attn_dist\n",
        "\n",
        "    # print(\"Before decoder\")\n",
        "    for t in range(max_length_summaries-1):\n",
        "      # print(t)\n",
        "      decoder_initial_state = decoder.initialize_hidden_state(BATCH_SIZE, dec_h, dec_c)\n",
        "      input_t = dec_emb[:, t, :] \n",
        "      # print(len(decoder_initial_state))\n",
        "      # print(input_t.shape)\n",
        "      # print(cov.shape)\n",
        "      # print(enc_output.shape)\n",
        "      # print(inp.shape)\n",
        "      # print(dec_h.shape)\n",
        "      # print(\"cell before\")\n",
        "      # print(dec_c.shape)\n",
        "      vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(input_t, decoder_initial_state, cov, enc_output, inp)\n",
        "      # print(\"cell after\")\n",
        "      # print(dec_c.shape)\n",
        "      # print(\"Out of the decoder\")\n",
        "      # print()\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "      # attn_dist, vocab_dist = pointerGen(context_vec, input_t, outputs, vocab_dist, attn_dist)\n",
        "      \n",
        "      # final_dist = scatter_add(vocab_dist, inp, attn_dist)\n",
        "      # final_dist = tf.squeeze(final_dist, -1) \n",
        "      final_dists.append(vocab_dist)\n",
        "      attn_dists.append(attn_dist)\n",
        "      coverages.append(cov)\n",
        "    # print(\"Out of decoder finally\")\n",
        "    final_dists = tf.stack(final_dists, axis=-1)\n",
        "    attn_dists = tf.stack(attn_dists, axis=-1)\n",
        "    coverages = tf.stack(coverages, axis=-1)\n",
        "    final_dists = tf.reshape(final_dists, [BATCH_SIZE, max_length_summaries-1, vocab_size])\n",
        "\n",
        "    # print(lstm_outputs.shape)\n",
        "    # print(vocab_dist.shape)\n",
        "    # print(outputs.shape)\n",
        "    logits = final_dists\n",
        "    # print(logits.shape)\n",
        "    # print(\"Before loss\")\n",
        "    loss = loss_function(real, logits)\n",
        "    # print(\"After loss\")\n",
        "    # loss = loss / (max_length_summaries - 1)\n",
        "    # print(\"Before cov loss\")\n",
        "    cov_loss = coverage_loss(attn_dist, cov)\n",
        "    # print(\"After cov loss\")\n",
        "    loss = loss + cov_weight * cov_loss\n",
        "    # print(\"After loss\")\n",
        "    # print()\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables), experimental_aggregate_gradients=False)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zO5TQMAkqTJ4",
        "outputId": "59521d2f-a712-4597-cb6c-161a0cf70dc6"
      },
      "source": [
        "EPOCHS = 40\n",
        "count = 1\n",
        "steps_per_epoch = num_examples//BATCH_SIZE\n",
        "# steps_per_epoch = 1\n",
        "cov = np.zeros((BATCH_SIZE, max_length_articles))\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden, cov)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print('Epoch {} Batch {} Loss {}'.format(count,\n",
        "                                                   batch,\n",
        "                                                   batch_loss))\n",
        "  # saving (checkpoint) the model every epoch\n",
        "  if (epoch + 1) % 1 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {}'.format(count,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  # print(\"Learning Rate: \" + str(optimizer.lr.initial_learning_rate))\n",
        "  save_weights_in_drive(count)\n",
        "  count += 1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 29 Batch 400 Loss 2.061774492263794\n",
            "Epoch 29 Batch 800 Loss 2.611629009246826\n",
            "Epoch 29 Batch 1200 Loss 2.1147279739379883\n",
            "Epoch 29 Batch 1600 Loss 2.459463119506836\n",
            "Epoch 29 Batch 2000 Loss 2.1500508785247803\n",
            "Epoch 29 Loss 2.2958924770355225\n",
            "Time taken for 1 epoch 856.5424525737762 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 2.4353320598602295\n",
            "Epoch 30 Batch 400 Loss 2.057389497756958\n",
            "Epoch 30 Batch 800 Loss 2.5910866260528564\n",
            "Epoch 30 Batch 1200 Loss 2.1008386611938477\n",
            "Epoch 30 Batch 1600 Loss 2.426307201385498\n",
            "Epoch 30 Batch 2000 Loss 2.1380252838134766\n",
            "Epoch 30 Loss 2.275987148284912\n",
            "Time taken for 1 epoch 857.5028221607208 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 2.405977964401245\n",
            "Epoch 31 Batch 400 Loss 2.04223895072937\n",
            "Epoch 31 Batch 800 Loss 2.5694403648376465\n",
            "Epoch 31 Batch 1200 Loss 2.0951988697052\n",
            "Epoch 31 Batch 1600 Loss 2.4092957973480225\n",
            "Epoch 31 Batch 2000 Loss 2.116467237472534\n",
            "Epoch 31 Loss 2.2620930671691895\n",
            "Time taken for 1 epoch 856.676506280899 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 2.394976854324341\n",
            "Epoch 32 Batch 400 Loss 2.0252435207366943\n",
            "Epoch 32 Batch 800 Loss 2.5588817596435547\n",
            "Epoch 32 Batch 1200 Loss 2.070108652114868\n",
            "Epoch 32 Batch 1600 Loss 2.387024402618408\n",
            "Epoch 32 Batch 2000 Loss 2.100466728210449\n",
            "Epoch 32 Loss 2.2410664558410645\n",
            "Time taken for 1 epoch 856.5649721622467 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 2.3842341899871826\n",
            "Epoch 33 Batch 400 Loss 2.012336254119873\n",
            "Epoch 33 Batch 800 Loss 2.5293617248535156\n",
            "Epoch 33 Batch 1200 Loss 2.0462822914123535\n",
            "Epoch 33 Batch 1600 Loss 2.360032796859741\n",
            "Epoch 33 Batch 2000 Loss 2.080383062362671\n",
            "Epoch 33 Loss 2.223220109939575\n",
            "Time taken for 1 epoch 856.6635341644287 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 2.3703906536102295\n",
            "Epoch 34 Batch 400 Loss 1.998976707458496\n",
            "Epoch 34 Batch 800 Loss 2.5260465145111084\n",
            "Epoch 34 Batch 1200 Loss 2.0798094272613525\n",
            "Epoch 34 Batch 1600 Loss 2.3685970306396484\n",
            "Epoch 34 Batch 2000 Loss 2.0754141807556152\n",
            "Epoch 34 Loss 2.2299647331237793\n",
            "Time taken for 1 epoch 856.5055792331696 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 2.34516978263855\n",
            "Epoch 35 Batch 400 Loss 1.9828217029571533\n",
            "Epoch 35 Batch 800 Loss 2.513875722885132\n",
            "Epoch 35 Batch 1200 Loss 2.031874656677246\n",
            "Epoch 35 Batch 1600 Loss 2.3240771293640137\n",
            "Epoch 35 Batch 2000 Loss 2.0527701377868652\n",
            "Epoch 35 Loss 2.198547840118408\n",
            "Time taken for 1 epoch 856.1143598556519 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 2.3374428749084473\n",
            "Epoch 36 Batch 400 Loss 1.9627071619033813\n",
            "Epoch 36 Batch 800 Loss 2.492326498031616\n",
            "Epoch 36 Batch 1200 Loss 2.0191762447357178\n",
            "Epoch 36 Batch 1600 Loss 2.3282968997955322\n",
            "Epoch 36 Batch 2000 Loss 2.0892865657806396\n",
            "Epoch 36 Loss 2.192345380783081\n",
            "Time taken for 1 epoch 855.0437808036804 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 2.351125717163086\n",
            "Epoch 37 Batch 400 Loss 1.9666469097137451\n",
            "Epoch 37 Batch 800 Loss 2.4918651580810547\n",
            "Epoch 37 Batch 1200 Loss 2.0018157958984375\n",
            "Epoch 37 Batch 1600 Loss 2.314514636993408\n",
            "Epoch 37 Batch 2000 Loss 2.0296738147735596\n",
            "Epoch 37 Loss 2.1772053241729736\n",
            "Time taken for 1 epoch 855.0069224834442 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 2.299297332763672\n",
            "Epoch 38 Batch 400 Loss 1.939381718635559\n",
            "Epoch 38 Batch 800 Loss 2.471804618835449\n",
            "Epoch 38 Batch 1200 Loss 1.9715508222579956\n",
            "Epoch 38 Batch 1600 Loss 2.2879700660705566\n",
            "Epoch 38 Batch 2000 Loss 1.9864798784255981\n",
            "Epoch 38 Loss 2.152775526046753\n",
            "Time taken for 1 epoch 855.4129683971405 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 2.2741217613220215\n",
            "Epoch 39 Batch 400 Loss 1.9133402109146118\n",
            "Epoch 39 Batch 800 Loss 2.475492238998413\n",
            "Epoch 39 Batch 1200 Loss 1.9802213907241821\n",
            "Epoch 39 Batch 1600 Loss 2.2779908180236816\n",
            "Epoch 39 Batch 2000 Loss 1.9845150709152222\n",
            "Epoch 39 Loss 2.1414122581481934\n",
            "Time taken for 1 epoch 855.1117894649506 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 2.2780017852783203\n",
            "Epoch 40 Batch 400 Loss 1.9203670024871826\n",
            "Epoch 40 Batch 800 Loss 2.469104766845703\n",
            "Epoch 40 Batch 1200 Loss 1.9519537687301636\n",
            "Epoch 40 Batch 1600 Loss 2.2558631896972656\n",
            "Epoch 40 Batch 2000 Loss 1.9890013933181763\n",
            "Epoch 40 Loss 2.127476215362549\n",
            "Time taken for 1 epoch 856.3958766460419 sec\n",
            "\n",
            "Epoch 1 Batch 0 Loss 2.2778007984161377\n",
            "Epoch 1 Batch 400 Loss 1.900436520576477\n",
            "Epoch 1 Batch 800 Loss 2.453195571899414\n",
            "Epoch 1 Batch 1200 Loss 1.9567246437072754\n",
            "Epoch 1 Batch 1600 Loss 2.2533724308013916\n",
            "Epoch 1 Batch 2000 Loss 1.9646649360656738\n",
            "Epoch 1 Loss 2.1186716556549072\n",
            "Time taken for 1 epoch 857.1099238395691 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.2730836868286133\n",
            "Epoch 2 Batch 400 Loss 1.887930154800415\n",
            "Epoch 2 Batch 800 Loss 2.4195454120635986\n",
            "Epoch 2 Batch 1200 Loss 1.9734296798706055\n",
            "Epoch 2 Batch 1600 Loss 2.238391399383545\n",
            "Epoch 2 Batch 2000 Loss 1.949585199356079\n",
            "Epoch 2 Loss 2.109776020050049\n",
            "Time taken for 1 epoch 856.4107139110565 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.250497817993164\n",
            "Epoch 3 Batch 400 Loss 1.8785827159881592\n",
            "Epoch 3 Batch 800 Loss 2.414717197418213\n",
            "Epoch 3 Batch 1200 Loss 1.9385045766830444\n",
            "Epoch 3 Batch 1600 Loss 2.235928535461426\n",
            "Epoch 3 Batch 2000 Loss 1.945585012435913\n",
            "Epoch 3 Loss 2.0956296920776367\n",
            "Time taken for 1 epoch 857.0157401561737 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.230830669403076\n",
            "Epoch 4 Batch 400 Loss 1.8729490041732788\n",
            "Epoch 4 Batch 800 Loss 2.400534152984619\n",
            "Epoch 4 Batch 1200 Loss 1.9229347705841064\n",
            "Epoch 4 Batch 1600 Loss 2.2587890625\n",
            "Epoch 4 Batch 2000 Loss 3.2926931381225586\n",
            "Epoch 4 Loss 2.1870689392089844\n",
            "Time taken for 1 epoch 858.190333366394 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 3.7448530197143555\n",
            "Epoch 5 Batch 400 Loss 2.7334768772125244\n",
            "Epoch 5 Batch 800 Loss 3.355179786682129\n",
            "Epoch 5 Batch 1200 Loss 2.7756893634796143\n",
            "Epoch 5 Batch 1600 Loss 3.072101354598999\n",
            "Epoch 5 Batch 2000 Loss 2.9108922481536865\n",
            "Epoch 5 Loss 3.046372890472412\n",
            "Time taken for 1 epoch 860.9537813663483 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 3.331420421600342\n",
            "Epoch 6 Batch 400 Loss 2.6096677780151367\n",
            "Epoch 6 Batch 800 Loss 3.2397284507751465\n",
            "Epoch 6 Batch 1200 Loss 2.679368734359741\n",
            "Epoch 6 Batch 1600 Loss 2.981748104095459\n",
            "Epoch 6 Batch 2000 Loss 2.8074750900268555\n",
            "Epoch 6 Loss 2.9030396938323975\n",
            "Time taken for 1 epoch 858.5646162033081 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 3.1794445514678955\n",
            "Epoch 7 Batch 400 Loss 2.539372205734253\n",
            "Epoch 7 Batch 800 Loss 3.148402690887451\n",
            "Epoch 7 Batch 1200 Loss 2.585615873336792\n",
            "Epoch 7 Batch 1600 Loss 2.9117300510406494\n",
            "Epoch 7 Batch 2000 Loss 2.737490653991699\n",
            "Epoch 7 Loss 2.8100597858428955\n",
            "Time taken for 1 epoch 859.4314947128296 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 3.0702688694000244\n",
            "Epoch 8 Batch 400 Loss 2.4831416606903076\n",
            "Epoch 8 Batch 800 Loss 3.069370746612549\n",
            "Epoch 8 Batch 1200 Loss 2.5008251667022705\n",
            "Epoch 8 Batch 1600 Loss 2.8605079650878906\n",
            "Epoch 8 Batch 2000 Loss 2.6480140686035156\n",
            "Epoch 8 Loss 2.7344608306884766\n",
            "Time taken for 1 epoch 856.7484366893768 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 2.962838888168335\n",
            "Epoch 9 Batch 400 Loss 2.419139862060547\n",
            "Epoch 9 Batch 800 Loss 3.0188987255096436\n",
            "Epoch 9 Batch 1200 Loss 2.4346020221710205\n",
            "Epoch 9 Batch 1600 Loss 2.829444169998169\n",
            "Epoch 9 Batch 2000 Loss 2.5913050174713135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1fdb3c1cec0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gI8_gCNJ_tQ"
      },
      "source": [
        "# Epoch 1 Loss 1.283766269683838\n",
        "def evaluate_sentence(sentence):\n",
        "    sentence = data.preprocess(sentence)\n",
        "    inputs = data.tokenizer.texts_to_sequences([sentence])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                          maxlen=max_length_articles,\n",
        "                                                          padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    inference_batch_size = inputs.shape[0]\n",
        "    encoder.trainable = False\n",
        "    decoder.trainable = False\n",
        "    # enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size, units))]\n",
        "    enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units)), tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "    decoded_seq = np.zeros((1,max_length_summaries))\n",
        "    decoded_seq[0,0]=word_index['<start>']\n",
        "    li_dec = decoded_seq\n",
        "    decoded_seq_word = '<start>'\n",
        "\n",
        "    li=[]\n",
        "    len_pred_summary = max_length_summaries - 2\n",
        "    # decoder_initial_state = decoder.initialize_hidden_state(BATCH_SIZE, enc_h, enc_c)\n",
        "    # dec_emb = decoder.embedding(decoded_seq)\n",
        "    # vocab_dist, outputs, lstm_outputs, dec_h, dec_c = decoder(dec_emb, decoder_initial_state)\n",
        "    # print(vocab_dist.shape)\n",
        "    # ans_arr = np.argmax(vocab_dist, axis = 1)\n",
        "    # print(ans_arr)\n",
        "\n",
        "    dec_h = enc_h\n",
        "    dec_c = enc_c\n",
        "    dec_emb = decoder.embedding(decoded_seq)\n",
        "    ans_arr = []\n",
        "    cov = tf.zeros([1, max_length_articles], tf.float32)\n",
        "    for t in range(max_length_summaries-1):\n",
        "      decoder_initial_state = decoder.initialize_hidden_state(1, dec_h, dec_c)\n",
        "      input_t = dec_emb[:, t, :] \n",
        "      vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(input_t, decoder_initial_state, cov, enc_out, inp)\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "      ans_arr.append(np.argmax(vocab_dist, axis = 1))\n",
        "    \n",
        "    # print(vocab_dist.shape)\n",
        "    # ans_arr = np.argmax(vocab_dist, axis = 1)\n",
        "    # print(ans_arr)\n",
        "    encoder.trainable = True\n",
        "    decoder.trainable = True\n",
        "    return ans_arr\n",
        "\n",
        "    # while decoded_seq_word !='<end>' and len_pred_summary>=0:\n",
        "        \n",
        "    #     decoded_seq, h,c = decoder(decoded_seq, decoder_initial_state)\n",
        "    #     print(decoded_seq[0][0][i].shape)\n",
        "    #     decoded_seq = np.argmax(decoded_seq[0][0][i])\n",
        "    #     print(decoded_seq)\n",
        "    #     decoded_seq_word = reverse_word_index.get(decoded_seq, 0)\n",
        "    #     # decoded_seq = np.zeros((1,64))\n",
        "    #     li_dec[0,i] = word_index.get(decoded_seq_word, 0)\n",
        "    #     decoded_seq = li_dec\n",
        "      \n",
        "    #     e_h = h\n",
        "    #     e_c = c\n",
        "    #     li.append(decoded_seq_word)\n",
        "        \n",
        "    #     len_pred_summary = len_pred_summary-1\n",
        "    #     i = i+1\n",
        "    \n",
        "    # # li.remove('<end>')\n",
        "    # out_final = \" \".join(li)\n",
        "    \n",
        "    # return out_final\n",
        "\n",
        "def summarize(sentence):\n",
        "  result = evaluate_sentence(sentence)\n",
        "  result = data.tokenizer.sequences_to_texts(result)\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(\" \".join(result)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZgTmt3iQIZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf47b46-4b35-4c34-9ba8-d99fc53cf760"
      },
      "source": [
        "test_sentence = \"There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahino’s nanny. Fletcher’s unveiling as the deadline day signing from Manchester United was almost eclipsed by the twenty-one-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahino’s senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford.\"\n",
        "summarize(test_sentence)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahino’s nanny. Fletcher’s unveiling as the deadline day signing from Manchester United was almost eclipsed by the twenty-one-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahino’s senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford.\n",
            "Predicted translation: nish pavlos <OOV> maxx weirdly ridding weirdly weirdly certainties jauch weirdly coastlines weirdly maxx joaan jauch certainties joaan earplugs kulaybi kulaybi kulaybi weirdly sloths footbonaut borrower rimmer gerson borrower soi scurrying kangaroos discolouration discolouration seductively weirdly interjected freeney interjected shareif comprehensives selig moniz victimless disguises weirdly weirdly basu basu sworn bosanek hribal lally flinching calveras labyrinth methanol clever labyrinth clever clever ignorance ignorance checkpoints teary rectum rakes harbouring goodhead postecoglou afghani afghani jauch jaunts jauch semitic seminary uhre longfellow longfellow jauch jauch spokesmen jauch jauch longfellow kuffar publican publican orson parliament crips publican hydroelectric publican schepp publican quintana juxtaposed soza soza mcadams mcadams schaaf schaaf earpiece earshot livonia swindling swindling localised illawarra illawarra fandom fandom homing publican migrated elphicke takeovers assads elphicke elphicke elphicke elphicke guizers stare\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQGJGfQ5ANd2"
      },
      "source": [
        "# saving weights\n",
        "!cp \"/content/training_checkpoints/checkpoint\" \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights\"\n",
        "!cp \"/content/training_checkpoints/ckpt-13.data-00000-of-00001\" \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights\"\n",
        "!cp \"/content/training_checkpoints/ckpt-13.index\" \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-oOPZelHcBk",
        "outputId": "957bfa4b-c332-4bb0-a47f-2aabeab1dda0"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/checkpoint\" \"/content/training_checkpoints/\"\n",
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-5.data-00000-of-00001\" \"/content/training_checkpoints/\"\n",
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-5.index\" \"/content/training_checkpoints/\"\n",
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1e0c19e9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1IyuDbx5qXQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}