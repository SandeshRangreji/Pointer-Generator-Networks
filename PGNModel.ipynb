{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PGNModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "497f9ea8bab94eff885619663b20f6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80514dda438d471195f33e183e1c660b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88f05176833443dd848cb69cbb26cfff",
              "IPY_MODEL_fd8dc523323648c191729aa74e04bec0"
            ]
          }
        },
        "80514dda438d471195f33e183e1c660b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88f05176833443dd848cb69cbb26cfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_777ca43745b6420fb06239aee479a5df",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c3cb14a849d4bd4aa4b995015ce452c"
          }
        },
        "fd8dc523323648c191729aa74e04bec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5a6179852924390b84c63a78d06cedb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [01:15&lt;00:00, 15.06s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76874509b78048fe92b72e77dbb7bf4c"
          }
        },
        "777ca43745b6420fb06239aee479a5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c3cb14a849d4bd4aa4b995015ce452c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5a6179852924390b84c63a78d06cedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76874509b78048fe92b72e77dbb7bf4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db5db73dba754519aa67ef8301bdb527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_715c2bbefbe44d3a9765b59af40d356a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43345bf2164940f08d9ca8122402c504",
              "IPY_MODEL_3cbe1233ba1b4b2eb43704236498a523"
            ]
          }
        },
        "715c2bbefbe44d3a9765b59af40d356a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43345bf2164940f08d9ca8122402c504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dce1b60a3474253a61cfb294fc9199c",
            "_dom_classes": [],
            "description": "Dl Size...: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_379a717c86ea48f0b9cd85144c37abea"
          }
        },
        "3cbe1233ba1b4b2eb43704236498a523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_085c73d106f949f7806940c79a67b3f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/? [01:15&lt;00:00,  7.40 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_541b06fecf9f4d4395c64e157e8cbd1d"
          }
        },
        "9dce1b60a3474253a61cfb294fc9199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "379a717c86ea48f0b9cd85144c37abea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "085c73d106f949f7806940c79a67b3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "541b06fecf9f4d4395c64e157e8cbd1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca92ca9e63f14fde8a6116a760b237e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffeb8e1172e54632aca2d9783e8b64ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4fc1f2142394492bc8c323966eb949b",
              "IPY_MODEL_99ebb0f2947046398d2749a73a403bc5"
            ]
          }
        },
        "ffeb8e1172e54632aca2d9783e8b64ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4fc1f2142394492bc8c323966eb949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75beab1d89e1446a8818f20f8820e14c",
            "_dom_classes": [],
            "description": "Extraction completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22c2cda7ce57459da7fd93f05b96b8f9"
          }
        },
        "99ebb0f2947046398d2749a73a403bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b477678f789c4957925dcb2915e96573",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [01:15&lt;00:00, 37.62s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ff8e7f344f1495880d6293a2b7ed20e"
          }
        },
        "75beab1d89e1446a8818f20f8820e14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22c2cda7ce57459da7fd93f05b96b8f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b477678f789c4957925dcb2915e96573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ff8e7f344f1495880d6293a2b7ed20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bea334b49714652b1ba74c0ea95c1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60984d2989c2426c809112672d7e3017",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_833dcd23efb442a793629de78041dd49",
              "IPY_MODEL_3ea99edc1ad345fe959fc51c5b7916f2"
            ]
          }
        },
        "60984d2989c2426c809112672d7e3017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "833dcd23efb442a793629de78041dd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ae527f330fd460eb71680a57d90b77f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec57f2aae9f7450bae2bba8e4a08cfce"
          }
        },
        "3ea99edc1ad345fe959fc51c5b7916f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_428d188118b149fc9d41ef87ab9c00ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 287113/0 [02:58&lt;00:00, 1266.53 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b55c4346ea81438f9ec8a5df14d332c6"
          }
        },
        "6ae527f330fd460eb71680a57d90b77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec57f2aae9f7450bae2bba8e4a08cfce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "428d188118b149fc9d41ef87ab9c00ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b55c4346ea81438f9ec8a5df14d332c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "351f40e8d5fe4e29b325125bca7e58d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1ea750513e4477c940a01368ea9a4aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6ac861d01f246f19f5f0c9cda144ef1",
              "IPY_MODEL_5b2fb579f5524e56b7c86cb3d3755810"
            ]
          }
        },
        "e1ea750513e4477c940a01368ea9a4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6ac861d01f246f19f5f0c9cda144ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89c138965e9143808057618ce422b52c",
            "_dom_classes": [],
            "description": " 99%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 287113,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 284705,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1e298595ce046ca998462f2cab86648"
          }
        },
        "5b2fb579f5524e56b7c86cb3d3755810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_181c453a0c034d888844b1cf4da5c40f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 284705/287113 [00:07&lt;00:00, 59413.44 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5541438afd2f468e9b083b9edce9f86f"
          }
        },
        "89c138965e9143808057618ce422b52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1e298595ce046ca998462f2cab86648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "181c453a0c034d888844b1cf4da5c40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5541438afd2f468e9b083b9edce9f86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86f47dc02c2d49e28c318cef52a7b765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d75a6508ce0b421cbe95f43e7db87738",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e11350e701b44499b3e2c6a3355a9bba",
              "IPY_MODEL_67772d2479fe486e8ba840d8ab3a87f4"
            ]
          }
        },
        "d75a6508ce0b421cbe95f43e7db87738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e11350e701b44499b3e2c6a3355a9bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a0019f0ca584ebaa4de6cb7dc557334",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b40d2d64a8594c039b7777ccc51cd413"
          }
        },
        "67772d2479fe486e8ba840d8ab3a87f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79c9c4295d564db8a6f240fba9eef3b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13368/0 [00:07&lt;00:00, 1730.20 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7564f862f47c4127a1c91c9124effc37"
          }
        },
        "5a0019f0ca584ebaa4de6cb7dc557334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b40d2d64a8594c039b7777ccc51cd413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79c9c4295d564db8a6f240fba9eef3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7564f862f47c4127a1c91c9124effc37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0595fbcd0544e6c88531b4bbc092ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9509ba7d81fc43f3b08ba152ddb038dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f323253ca79450d83ed966b547711ce",
              "IPY_MODEL_523576930c564fcb86642b4182aabebf"
            ]
          }
        },
        "9509ba7d81fc43f3b08ba152ddb038dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f323253ca79450d83ed966b547711ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cebe553d78044b38b328fb7651ac7b79",
            "_dom_classes": [],
            "description": " 73%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 13368,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9805,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d224ba014a9d4198b51fe45fbf326340"
          }
        },
        "523576930c564fcb86642b4182aabebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b26f30ede73438caf651d89071cc07a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9805/13368 [00:00&lt;00:00, 98044.48 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f80e7f0e557e419ea221d0b2e6e3bbfc"
          }
        },
        "cebe553d78044b38b328fb7651ac7b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d224ba014a9d4198b51fe45fbf326340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b26f30ede73438caf651d89071cc07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f80e7f0e557e419ea221d0b2e6e3bbfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a90e6a7add448159359cd8ef54ad694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b158b684dbdd485f95e2d1e4cfa3a7dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_405a2d705e4a45de9b5affdde18595b8",
              "IPY_MODEL_45cd061020ec42eaba586255a755ada7"
            ]
          }
        },
        "b158b684dbdd485f95e2d1e4cfa3a7dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "405a2d705e4a45de9b5affdde18595b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca05aa7115d64517b120f77e6883c2b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dde16060000c4aa4903ad290642c99c8"
          }
        },
        "45cd061020ec42eaba586255a755ada7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52341356b2804846acbf3d1c8147871c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11490/0 [00:06&lt;00:00, 1674.97 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9da8ee58c844be198ede5808f0de2d7"
          }
        },
        "ca05aa7115d64517b120f77e6883c2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dde16060000c4aa4903ad290642c99c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52341356b2804846acbf3d1c8147871c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9da8ee58c844be198ede5808f0de2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0cff7598dd74173b7d3dabb3ac1c735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6d02d73d1ea4fa2a0b123d83484197f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65880fa0de9341cba7170079c9449d3c",
              "IPY_MODEL_5b383ab626ff414db46e16f7df93258d"
            ]
          }
        },
        "a6d02d73d1ea4fa2a0b123d83484197f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65880fa0de9341cba7170079c9449d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f464d475b834d15baef06ca56e042b3",
            "_dom_classes": [],
            "description": " 88%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 11490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10090,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61643b6cebc54fa89c66c1fb9197ffca"
          }
        },
        "5b383ab626ff414db46e16f7df93258d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b94a3f6b06834abda7838b9ce9a3ef4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10090/11490 [00:02&lt;00:00, 100895.77 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe47b7bc637c40b2bd03fc8a417fad31"
          }
        },
        "7f464d475b834d15baef06ca56e042b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61643b6cebc54fa89c66c1fb9197ffca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b94a3f6b06834abda7838b9ce9a3ef4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe47b7bc637c40b2bd03fc8a417fad31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandeshRangreji/Pointer-Generator-Networks/blob/main/PGNModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFe8Tuv1j1Vf",
        "outputId": "43f20245-635a-4acf-a40f-9b0f4c81bd75"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 17 12:33:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB66MTa6j-zW",
        "outputId": "cb9d4cee-c8cf-41da-b6e8-d052379f3e64"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIOujJRQFsjR",
        "outputId": "e4684f01-91db-4cc8-a64d-ff8e72d2324a"
      },
      "source": [
        "pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 27.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 22.0MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 15.2MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 13.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ROq-CnaCxiy",
        "outputId": "3eb4a811-de98-471e-f28f-f7ebc4d45160"
      },
      "source": [
        "pip install --upgrade tensorflow-lattice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-lattice\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/35/3cb42ede037885c24010ad69a128318f88b159a45e7508d2b82666a1f193/tensorflow_lattice-2.0.8-py2.py3-none-any.whl (225kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 27.1MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 35.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 23.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 51kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 61kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 71kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 81kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 102kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 112kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 122kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 133kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 143kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 153kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 163kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 174kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 184kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 194kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 204kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 215kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.1.5)\n",
            "Collecting dm-sonnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/28/9185afffefb655ef1a29f4b84aa9f656826408ca2d1b9ffeba81fbfd40ec/dm_sonnet-2.0.0-py3-none-any.whl (254kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: sklearn in /usr/local/lib/python3.7/dist-packages (from tensorflow-lattice) (0.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow-lattice) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow-lattice) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: dm-tree>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (0.1.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->tensorflow-lattice) (0.8.9)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-lattice) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->tensorflow-lattice) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->tensorflow-lattice) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->tensorflow-lattice) (1.0.1)\n",
            "Installing collected packages: dm-sonnet, tensorflow-lattice\n",
            "Successfully installed dm-sonnet-2.0.0 tensorflow-lattice-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVJ2Zjl2e13P"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_lattice as tfl\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import re\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GypFb5xFgL-S",
        "outputId": "d6e27a75-79de-46d7-bc50-8d503a5e54ba"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd8EHJ67go_u",
        "outputId": "bd6a5bd5-fc0a-46b0-b197-a72ed05b81ad"
      },
      "source": [
        "# unzips Glove word embeddings\n",
        "!unrar x \"/content/drive/MyDrive/Pointer Generator Networks/glove.6B.200d.rar\" -d \"/content/PGN/data/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/Pointer Generator Networks/glove.6B.200d.rar\n",
            "\n",
            "Creating    /content/PGN                                              OK\n",
            "Creating    /content/PGN/data                                         OK\n",
            "Extracting  /content/PGN/data/glove.6B.200d.txt                          \b\b\b\b  1%\b\b\b\b  3%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  8%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 13%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 18%\b\b\b\b 20%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 25%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 30%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 35%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 40%\b\b\b\b 42%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 47%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 52%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 57%\b\b\b\b 59%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 64%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 69%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 74%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 79%\b\b\b\b 81%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 86%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 91%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 96%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5gXu4Z1lEOz"
      },
      "source": [
        "# class to handle data loading, splitting, preprocessing, tokenization\n",
        "class Data:\n",
        "\n",
        "  def __init__(self, vocab_size, oov_token):\n",
        "    # dictionary for contractions\n",
        "    self.tokenizer = Tokenizer(num_words = vocab_size, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token=oov_token)\n",
        "    self.contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "  # function to perform contractions\n",
        "  def split_contractions(self, sentence):\n",
        "    # parameters:\n",
        "    # sentence: article/summary (string)\n",
        "    # making a list of words from the article/summary\n",
        "    # return: article/summary after contractions (string)\n",
        "    li_sentence = sentence.split(' ')\n",
        "    # iterating through each word and replacing the contracted word if it is present in contraction dictionary\n",
        "    for i in range(len(li_sentence)):\n",
        "      li_sentence[i] = self.contractions.get(li_sentence[i], li_sentence[i])\n",
        "    # combining the list to form a string again\n",
        "    sentence = ' '.join(li_sentence)\n",
        "    return sentence\n",
        "\n",
        "  # function to handle preprocessing of articles and summaries\n",
        "  def preprocess(self, sentence):\n",
        "    # parameters:\n",
        "    # sentence: article or summary to be processed\n",
        "    # returns:\n",
        "    # sentence: cleaned article/summary\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    sentence = self.split_contractions(sentence)\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = \"<sos> \" + sentence\n",
        "    sentence = sentence.replace(\" . \", \" <sos> <eos> \")\n",
        "    sentence = sentence[:len(sentence) - 7]\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    # removing trailing spaces\n",
        "    sentence = sentence.lower().strip()\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "    return sentence  \n",
        "  \n",
        "  # splitting data into articles and summaries for training and testing\n",
        "  def split_data(self, dataset):\n",
        "    # parameters:\n",
        "    # dataset : tfds of cnn_dailymail dataset (bytes)\n",
        "    # returns:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (string)\n",
        "    train_articles = []\n",
        "    train_summaries = []\n",
        "    eval_articles = []\n",
        "    eval_summaries = []\n",
        "    # iterating through train dataset and storing articles and summaries seperately\n",
        "    for text in tfds.as_numpy(dataset['train']):\n",
        "      # decoding from bytes to string\n",
        "      article = self.preprocess(text['article'].decode(\"utf-8\"))\n",
        "      summaries = self.preprocess(text['highlights'].decode(\"utf-8\"))\n",
        "      train_articles.append(article)\n",
        "      train_summaries.append(summaries)\n",
        "\n",
        "    # iterating through validation dataset and storing articles and summaries seperately\n",
        "    for text in tfds.as_numpy(dataset['validation']):\n",
        "      # decoding from bytes to string\n",
        "      article = self.preprocess(text['article'].decode(\"utf-8\"))\n",
        "      summaries = self.preprocess(text['highlights'].decode(\"utf-8\"))\n",
        "      eval_articles.append(article)\n",
        "      eval_summaries.append(summaries)\n",
        "    return train_articles, train_summaries, eval_articles, eval_summaries\n",
        "\n",
        "  # function to tokenize data\n",
        "  def tokenize(self, train_articles, train_summaries, eval_articles, eval_summaries, vocab_size , embedding_dim, max_length_articles, max_length_summaries, truncating_type, padding_type, oov_token):\n",
        "    # parameters:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (string)\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimensions of word embeddings\n",
        "    # max_lengths_articles: number of words in the longest article\n",
        "    # max_lengths_summaries: number of words in the longest summary\n",
        "    # truncating_type: pre/post truncatation\n",
        "    # padding_type: pro/post padding\n",
        "    # oov_token: specifies what oov_token should be used\n",
        "    # return:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (sequences)\n",
        "    # initialize tokenizer\n",
        "    # fit tokenizer on training input (vocab)\n",
        "    self.tokenizer.fit_on_texts(train_articles)\n",
        "    # get word index from tokenizer\n",
        "    word_index = self.tokenizer.word_index\n",
        "    # tokenize articles for training \n",
        "    train_articles = self.tokenizer.texts_to_sequences(train_articles)\n",
        "    train_articles = pad_sequences(train_articles ,maxlen=max_length_articles, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize summaries for training \n",
        "    eval_articles = self.tokenizer.texts_to_sequences(eval_articles)\n",
        "    eval_articles = pad_sequences(eval_articles, maxlen=max_length_articles, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize articles for eval \n",
        "    train_summaries = self.tokenizer.texts_to_sequences(train_summaries)\n",
        "    train_summaries = pad_sequences(train_summaries ,maxlen=max_length_summaries, padding=padding_type, truncating=truncating_type)\n",
        "    # tokenize summaries for eval \n",
        "    eval_summaries = self.tokenizer.texts_to_sequences(eval_summaries)\n",
        "    eval_summaries = pad_sequences(eval_summaries, maxlen=max_length_summaries, padding=padding_type, truncating=truncating_type)\n",
        "    return train_articles, train_summaries, eval_articles, eval_summaries, word_index\n",
        "\n",
        "  # function to get a dictionery which is the reverse of the word_index\n",
        "  def get_reverse_word_index(self, word_index):\n",
        "    # parameters:\n",
        "    # word_index : { word : id }\n",
        "    # returns\n",
        "    # reverse_word_index : { id : word }\n",
        "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "    return reverse_word_index\n",
        "\n",
        "  # get important metrics of the dataset that is needed to build a model\n",
        "  def get_data_metrics(self):\n",
        "    # return:\n",
        "    # average length of articles, average length of summaries, length of longest article, length of longest summary\n",
        "    # loading dataset\n",
        "    ds = tfds.load(\"cnn_dailymail\")\n",
        "    # decoding and splitting dataset into train and eval articles and summaries\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries = self.split_data(ds)\n",
        "    train_article_sum = 0\n",
        "    max_article_len = 0\n",
        "    max_summary_len = 0\n",
        "    train_summaries_sum = 0\n",
        "    # iterating through dataset to count total number of words\n",
        "    for i in range(len(train_articles)):\n",
        "      # current article and summary length (no. of words)\n",
        "      article_len = len(train_articles[i].split())\n",
        "      summary_len = len(train_summaries[i].split())\n",
        "      # finding length of article with most number of words\n",
        "      if(article_len>max_article_len):\n",
        "        max_article_len = article_len\n",
        "      # finding length of summary with most number of words\n",
        "      if(summary_len>max_summary_len):\n",
        "        max_summary_len = summary_len\n",
        "      # calculating total number of words accross all articles and summary to calculate average\n",
        "      train_article_sum = train_article_sum + article_len\n",
        "      train_summaries_sum = train_summaries_sum + summary_len\n",
        "    return train_article_sum/len(train_articles), train_summaries_sum/len(train_summaries), max_article_len, max_summary_len \n",
        "\n",
        "  # function to load pretrained word embeddings and prepare them for embedding layer\n",
        "  def get_word_embeddings(self, word_index, vocab_size, embedding_dim):\n",
        "    # parameters:\n",
        "    # word_index: { word:id }\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimension of word embeddings\n",
        "    embeddings_index = {}\n",
        "    # opening and reading word embeddings from file\n",
        "    with open('/content/PGN/data/glove.6B.200d.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
        "\n",
        "    # converting word embeddings to matrix (weights for embedding layer) using word_index\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None and i<=vocab_size:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "    return embeddings_index, embeddings_matrix\n",
        "\n",
        "  # function to convert list of articles and summaries to iterable, batched datasets\n",
        "  def batch_datasets(self, train_articles, train_summaries, eval_articles, eval_summaries, BATCH_SIZE):\n",
        "    # parameters:\n",
        "    # train_articles, train_summaries, eval_articles, eval_summaries : lists of training and eval articles and summaries (sequences)\n",
        "    # BATCH_SIZE: size of one batch in the dataset\n",
        "    # return:\n",
        "    # train_dataset, val_dataset: dataset objects for training and evaluation, batched according to BATCH_SIZE\n",
        "    # making a dataset object from the train articles and summaries\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_articles, train_summaries))\n",
        "    # batching training dataset\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    # making a dataset object from the evaluation articles and summaries\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((eval_articles, eval_summaries))\n",
        "    # batching evaluation dataset\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "  def __call__(self, num_training_examples = 2048, vocab_size = 25000, embedding_dim = 200, max_length_articles = 2880, max_length_summaries = 1344, truncating_type='post', padding_type='post', oov_token='<OOV>', BATCH_SIZE=64):\n",
        "    # parameters:\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dim: dimensions of word embeddings\n",
        "    # max_lengths_articles: number of words in the longest article\n",
        "    # max_lengths_summaries: number of words in the longest summary\n",
        "    # truncating_type: pre/post truncatation\n",
        "    # padding_type: pro/post padding\n",
        "    # oov_token: specifies what oov_token should be used\n",
        "    # returns:\n",
        "    # train_dataset, val_dataset: dataset objects for training and evaluation, batched according to BATCH_SIZE\n",
        "    # word_index : { word : id }\n",
        "    # reverse_word_index : { id : word }\n",
        "\n",
        "    # loading data in bytes from tfds\n",
        "    ds=tfds.load(\"cnn_dailymail\")\n",
        "    # splitting data into train and test sets of articles and summaries\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries = self.split_data(ds)\n",
        "    # tokenizing data\n",
        "    train_articles, train_summaries, eval_articles, eval_summaries, word_index = self.tokenize(\n",
        "        train_articles[:num_training_examples], \n",
        "        train_summaries[:num_training_examples], \n",
        "        eval_articles[:2048], \n",
        "        eval_summaries[:2048],\n",
        "        vocab_size , \n",
        "        embedding_dim, \n",
        "        max_length_articles, \n",
        "        max_length_summaries, \n",
        "        truncating_type, \n",
        "        padding_type, \n",
        "        oov_token)\n",
        "    # vocab_size = len(word_index)\n",
        "    # converting list of articles to train and evaluation datasets that are in batches\n",
        "    train_dataset, validation_dataset = self.batch_datasets(train_articles, train_summaries, eval_articles, eval_summaries, BATCH_SIZE)\n",
        "    return train_dataset, validation_dataset, word_index, self.get_reverse_word_index(word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447,
          "referenced_widgets": [
            "497f9ea8bab94eff885619663b20f6f2",
            "80514dda438d471195f33e183e1c660b",
            "88f05176833443dd848cb69cbb26cfff",
            "fd8dc523323648c191729aa74e04bec0",
            "777ca43745b6420fb06239aee479a5df",
            "4c3cb14a849d4bd4aa4b995015ce452c",
            "d5a6179852924390b84c63a78d06cedb",
            "76874509b78048fe92b72e77dbb7bf4c",
            "db5db73dba754519aa67ef8301bdb527",
            "715c2bbefbe44d3a9765b59af40d356a",
            "43345bf2164940f08d9ca8122402c504",
            "3cbe1233ba1b4b2eb43704236498a523",
            "9dce1b60a3474253a61cfb294fc9199c",
            "379a717c86ea48f0b9cd85144c37abea",
            "085c73d106f949f7806940c79a67b3f4",
            "541b06fecf9f4d4395c64e157e8cbd1d",
            "ca92ca9e63f14fde8a6116a760b237e0",
            "ffeb8e1172e54632aca2d9783e8b64ba",
            "d4fc1f2142394492bc8c323966eb949b",
            "99ebb0f2947046398d2749a73a403bc5",
            "75beab1d89e1446a8818f20f8820e14c",
            "22c2cda7ce57459da7fd93f05b96b8f9",
            "b477678f789c4957925dcb2915e96573",
            "6ff8e7f344f1495880d6293a2b7ed20e",
            "2bea334b49714652b1ba74c0ea95c1a2",
            "60984d2989c2426c809112672d7e3017",
            "833dcd23efb442a793629de78041dd49",
            "3ea99edc1ad345fe959fc51c5b7916f2",
            "6ae527f330fd460eb71680a57d90b77f",
            "ec57f2aae9f7450bae2bba8e4a08cfce",
            "428d188118b149fc9d41ef87ab9c00ef",
            "b55c4346ea81438f9ec8a5df14d332c6",
            "351f40e8d5fe4e29b325125bca7e58d9",
            "e1ea750513e4477c940a01368ea9a4aa",
            "d6ac861d01f246f19f5f0c9cda144ef1",
            "5b2fb579f5524e56b7c86cb3d3755810",
            "89c138965e9143808057618ce422b52c",
            "a1e298595ce046ca998462f2cab86648",
            "181c453a0c034d888844b1cf4da5c40f",
            "5541438afd2f468e9b083b9edce9f86f",
            "86f47dc02c2d49e28c318cef52a7b765",
            "d75a6508ce0b421cbe95f43e7db87738",
            "e11350e701b44499b3e2c6a3355a9bba",
            "67772d2479fe486e8ba840d8ab3a87f4",
            "5a0019f0ca584ebaa4de6cb7dc557334",
            "b40d2d64a8594c039b7777ccc51cd413",
            "79c9c4295d564db8a6f240fba9eef3b4",
            "7564f862f47c4127a1c91c9124effc37",
            "d0595fbcd0544e6c88531b4bbc092ae4",
            "9509ba7d81fc43f3b08ba152ddb038dc",
            "5f323253ca79450d83ed966b547711ce",
            "523576930c564fcb86642b4182aabebf",
            "cebe553d78044b38b328fb7651ac7b79",
            "d224ba014a9d4198b51fe45fbf326340",
            "1b26f30ede73438caf651d89071cc07a",
            "f80e7f0e557e419ea221d0b2e6e3bbfc",
            "8a90e6a7add448159359cd8ef54ad694",
            "b158b684dbdd485f95e2d1e4cfa3a7dc",
            "405a2d705e4a45de9b5affdde18595b8",
            "45cd061020ec42eaba586255a755ada7",
            "ca05aa7115d64517b120f77e6883c2b2",
            "dde16060000c4aa4903ad290642c99c8",
            "52341356b2804846acbf3d1c8147871c",
            "a9da8ee58c844be198ede5808f0de2d7",
            "a0cff7598dd74173b7d3dabb3ac1c735",
            "a6d02d73d1ea4fa2a0b123d83484197f",
            "65880fa0de9341cba7170079c9449d3c",
            "5b383ab626ff414db46e16f7df93258d",
            "7f464d475b834d15baef06ca56e042b3",
            "61643b6cebc54fa89c66c1fb9197ffca",
            "b94a3f6b06834abda7838b9ce9a3ef4a",
            "fe47b7bc637c40b2bd03fc8a417fad31"
          ]
        },
        "id": "3OehanrRoj_u",
        "outputId": "829ed27c-b470-4c03-dd24-52bc29ab51cc"
      },
      "source": [
        "vocab_size = 50000\n",
        "# num_examples = 65536\n",
        "num_examples = 32768\n",
        "embedding_dim = 200\n",
        "max_length_articles = 1024\n",
        "max_length_summaries = 128\n",
        "truncating_type ='post'\n",
        "padding_type ='post'\n",
        "oov_token = \"<OOV>\"\n",
        "BATCH_SIZE = 8\n",
        "data = Data(vocab_size, oov_token)\n",
        "# load, split, batch data\n",
        "train_dataset, val_dataset, word_index, reverse_word_index = data(\n",
        "        num_examples,\n",
        "        vocab_size, \n",
        "        embedding_dim, \n",
        "        max_length_articles, \n",
        "        max_length_summaries, \n",
        "        truncating_type, \n",
        "        padding_type, \n",
        "        oov_token,\n",
        "        BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cnn_dailymail/plain_text/3.0.0 (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "497f9ea8bab94eff885619663b20f6f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db5db73dba754519aa67ef8301bdb527",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca92ca9e63f14fde8a6116a760b237e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bea334b49714652b1ba74c0ea95c1a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0.incompleteBOFGQU/cnn_dailymail-train.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "351f40e8d5fe4e29b325125bca7e58d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=287113.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86f47dc02c2d49e28c318cef52a7b765",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0.incompleteBOFGQU/cnn_dailymail-validation.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0595fbcd0544e6c88531b4bbc092ae4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=13368.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a90e6a7add448159359cd8ef54ad694",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0.incompleteBOFGQU/cnn_dailymail-test.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0cff7598dd74173b7d3dabb3ac1c735",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11490.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n",
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset cnn_dailymail downloaded and prepared to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBMPgFoEqxhD"
      },
      "source": [
        "# get word embeddings in the form of a matrix\n",
        "embeddings_index, embeddings_matrix = data.get_word_embeddings(word_index, vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzIxZw99RuAy",
        "outputId": "d6b0273a-11ee-4665-d0a5-1505752e63cf"
      },
      "source": [
        "embeddings_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50001, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3nKYCnZ7Tdw",
        "outputId": "86060a68-20f7-44fe-8ac7-6087e2a29809"
      },
      "source": [
        "# sample data from dataset\n",
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([8, 1024]), TensorShape([8, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTHLyeX_q9yO"
      },
      "source": [
        "# class for Encoder model\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, embeddings_matrix, hidden_dim):\n",
        "    # parameters:\n",
        "    # vocab_size: size of vocabulary\n",
        "    # embedding_dims: dimension of word embeddings\n",
        "    # enc_units: number of LSTM units in the encoder\n",
        "    # batch_sz: batch size of data\n",
        "    # embedding_matrix: word embeddings in the form of a matrix\n",
        "    super(Encoder, self).__init__()\n",
        "    # initializing model layers and some parameters of those layers\n",
        "    self.batch_sz = batch_sz\n",
        "    self.l1_enc_units = enc_units\n",
        "    self.l2_enc_units = enc_units//2\n",
        "    self.l3_enc_units = enc_units//4\n",
        "    # initializing embedding layer with pretrained word embeddings\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length_articles, weights=[embeddings_matrix], trainable=False)\n",
        "\n",
        "    ##________ LSTM layer in Encoder ------- ##\n",
        "    self.lstm_layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l1_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    self.lstm_layer_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l2_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    \n",
        "    self.lstm_layer_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.l3_enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform'))\n",
        "    self.reduce_h = tf.keras.layers.Dense(units = hidden_dim, use_bias=True)\n",
        "    self.reduce_c = tf.keras.layers.Dense(units = hidden_dim, use_bias=True)\n",
        "\n",
        "\n",
        "  # build encoder model\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output_1, forward_h1, forward_c1, backward_h1, backward_c1 = self.lstm_layer_1(x, initial_state = hidden )\n",
        "    output_2, forward_h2, forward_c2, backward_h2, backward_c2 = self.lstm_layer_2(output_1)\n",
        "    output_3, forward_h3, forward_c3, backward_h3, backward_c3 = self.lstm_layer_3(output_2)\n",
        "    # h = tf.concat([forward_h1, backward_h1], axis=-1)\n",
        "    # c = tf.concat([forward_c1, backward_c1], axis=-1)\n",
        "    # h = tf.concat([forward_h2, backward_h2], axis=-1)\n",
        "    # c = tf.concat([forward_c2, backward_c2], axis=-1)\n",
        "    h = tf.concat([forward_h3, backward_h3], axis=-1)\n",
        "    c = tf.concat([forward_c3, backward_c3], axis=-1)\n",
        "    final_h = tf.keras.activations.relu(self.reduce_h(h))\n",
        "    final_c = tf.keras.activations.relu(self.reduce_c(c))\n",
        "    return output_3, final_h, final_c\n",
        "\n",
        "  # initializing weights\n",
        "  def initialize_hidden_state(self):\n",
        "    return [tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units)), tf.zeros((self.batch_sz, self.l1_enc_units))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPPhp9Rju5vx",
        "outputId": "cc2ca34f-8ca9-462e-ece5-b6073106f0da"
      },
      "source": [
        "## Test Encoder Stack\n",
        "\n",
        "units = 256\n",
        "# dec_units = units//2\n",
        "dec_units = units\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE, embeddings_matrix, dec_units)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder h vector shape: (batch size, units) {}'.format(sample_h.shape))\n",
        "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (8, 1024, 512)\n",
            "Encoder h vector shape: (batch size, units) (8, 256)\n",
            "Encoder c vector shape: (batch size, units) (8, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0YP1g30zPV2"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.v = tf.keras.layers.Dense(units = 1, use_bias=False)                       # v\n",
        "    self.enc_proj = tf.keras.layers.Dense(units = hidden_dim*2, use_bias=False)      # W_h\n",
        "    self.dec_proj = tf.keras.layers.Dense(units = hidden_dim*2, use_bias=True)        # W_s, b_attn\n",
        "    self.w_c = tf.keras.layers.Dense(units = hidden_dim*2 , use_bias=False)                     # W_c\n",
        "\n",
        "  def __call__(self, dec_input, coverage, enc_hidden):\n",
        "    enc_feature = self.enc_proj(enc_hidden)         # [B x L x 2H]\n",
        "    dec_feature = self.dec_proj(dec_input)          # [B x 2H]\n",
        "    dec_feature = tf.expand_dims(dec_feature, 1)    # [B x 1 x 2H]\n",
        "    # print(enc_feature.shape)\n",
        "    # print(dec_feature.shape)\n",
        "    scores = enc_feature + dec_feature              # [B x L x 2H]\n",
        "\n",
        "    coverage = tf.expand_dims(coverage, -1)      # [B x L x 1]\n",
        "    cov_feature = self.w_c(coverage)            # [B x L x 2H]\n",
        "    scores = scores + cov_feature\n",
        "\n",
        "    scores = tf.keras.activations.tanh(scores)                     # [B x L x 2H]\n",
        "    scores = self.v(scores)                         # [B x L x 1]\n",
        "    scores = tf.squeeze(scores, -1)                     # [B x L]\n",
        "    attn_dist = tf.keras.activations.softmax(scores, axis = -1)               # [B x L]\n",
        "    return attn_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMfuORfuD4dz",
        "outputId": "50e97b4b-343d-4972-fcb3-4c2e10f46a2f"
      },
      "source": [
        "attention = Attention(dec_units)\n",
        "coverage = np.random.randn(BATCH_SIZE, max_length_articles)\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, dec_units))\n",
        "attn_dist = attention(sample_x, coverage, sample_output)\n",
        "print(attn_dist.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh__xZQ_1Lnf"
      },
      "source": [
        "class PointerGenerator(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(PointerGenerator, self).__init__()\n",
        "    self.w_h = tf.keras.layers.Dense(units = 1, use_bias=False) \n",
        "    self.w_s = tf.keras.layers.Dense(units = 1, use_bias=False) \n",
        "    self.w_x = tf.keras.layers.Dense(units = 1, use_bias=True) \n",
        "\n",
        "  def call(self, context_vec, dec_input, outputs, vocab_dist, attn_dist):\n",
        "    # Eq. (8) - Compute generation probability p_gen\n",
        "    context_feat = self.w_h(context_vec)                    # [B x 1]\n",
        "    decoder_feat = self.w_s(outputs)                              # [B x 1]\n",
        "    input_feat = self.w_x(dec_input)                          # [B x 1]\n",
        "    \n",
        "    gen_feat = context_feat + decoder_feat + input_feat\n",
        "    p_gen = tf.keras.activations.sigmoid(gen_feat)                         # [B x 1]\n",
        "\n",
        "    # Eq. (9) - Compute prob dist'n over extended vocabulary\n",
        "    vocab_dist = p_gen * vocab_dist                         # [B x V]\n",
        "    weighted_attn_dist = (1.0 - p_gen) * attn_dist          # [B x L]\n",
        "    return weighted_attn_dist, vocab_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDLkcSrGyTCK"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    # Embedding Layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    # Define the fundamental cell for decoder recurrent structure\n",
        "    self.rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
        "    # Define the attention layer\n",
        "    self.attention = Attention(self.dec_units)\n",
        "    # Define the Pointer Generator \n",
        "    # self.pointerGen = PointerGenerator()\n",
        "    # Fully Connected layers\n",
        "    self.v = tf.keras.layers.Dense(units = dec_units, use_bias=True)   # V, b\n",
        "    self.v_out = tf.keras.layers.Dense(units = vocab_size, use_bias=True)   # V', b'\n",
        "    \n",
        "  def initialize_hidden_state(self, batch_sz, sample_h, sample_c):\n",
        "    return [sample_h, sample_c]\n",
        "\n",
        "  def embedding(self, input):\n",
        "    return self.embedding(input)\n",
        "\n",
        "  def __call__(self, x, hidden, cov, enc_output, indices):  \n",
        "    # print(\"In decoder\")\n",
        "    hidden, cell = self.rnn_cell(x, hidden)\n",
        "    attn_dist = self.attention(hidden, cov, enc_output)\n",
        "    # The context vector is used later to compute generation probability\n",
        "    context_vec = tf.linalg.matmul(tf.expand_dims(attn_dist, 1), enc_output)   # [B x 1 x 2H]\n",
        "    context_vec = tf.math.reduce_sum(context_vec, axis = 1)                    # [B x 2H] \n",
        "    # Eq. (4)\n",
        "    output = self.v(tf.concat([hidden, context_vec], axis=-1))                # [B x 3H] -> [B x H]\n",
        "    output = self.v_out(output)                                                # [B x V]\n",
        "    vocab_dist = tf.keras.activations.softmax(output, axis=-1)                 # [B x V]\n",
        "    return vocab_dist, attn_dist, context_vec, output, cell[0], cell[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liyPdtoz7Wfl",
        "outputId": "805d2f1f-2c57-49df-9d4d-82bb6a139356"
      },
      "source": [
        "# Test decoder stack\n",
        "decoder = Decoder(vocab_size, embedding_dim, dec_units, BATCH_SIZE)\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, embedding_dim))\n",
        "hidden = decoder.initialize_hidden_state(BATCH_SIZE, sample_h, sample_c)\n",
        "cov_sample = np.zeros((BATCH_SIZE, max_length_articles))\n",
        "# sample_x = decoder.embedding(sample_x)\n",
        "vocab_dist, attn_dist, context_vec, sample_decoder_outputs, dec_h, dec_c = decoder(sample_x, hidden, cov_sample, sample_output, example_input_batch)\n",
        "\n",
        "pointerGen = PointerGenerator()\n",
        "print(\"Vocab Distribution Shape: \", vocab_dist.shape)\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.shape)\n",
        "# print(\"LSTM Outputs Shape: \", sample_lstm_out.shape)\n",
        "print(\"Decoder hidden state Shape: \", dec_h.shape)\n",
        "print(\"Decoder cell state Shape: \", dec_c.shape)\n",
        "print(\"Attention Distribution Shape: \", attn_dist.shape)\n",
        "print(\"Context Vector Shape: \", context_vec.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder Outputs Shape:  (8, 50000)\n",
            "Decoder hidden state Shape:  (8, 256)\n",
            "Decoder cell state Shape:  (8, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOVglv6JQSvm"
      },
      "source": [
        "def scatter_add(tensor, indices, updates):\n",
        "    original_tensor = tensor\n",
        "    # expand index value from vocab size\n",
        "    indices = tf.compat.v1.reshape(indices, shape=[-1, tf.shape(indices)[-1]])\n",
        "    indices_add = tf.compat.v1.expand_dims(tf.range(0, tf.shape(indices)[0], 1)*(tf.shape(tensor)[-1]), axis=-1)\n",
        "    indices += indices_add\n",
        "\n",
        "    # resize\n",
        "    tensor = tf.compat.v1.reshape(tensor, shape=[-1])\n",
        "    indices = tf.compat.v1.reshape(indices, shape=[-1, 1])\n",
        "    updates = tf.compat.v1.reshape(updates, shape=[-1])\n",
        "\n",
        "    #check_\n",
        "    \"\"\"\n",
        "    update = tensor.shape[indices.shape[-1]:]\n",
        "    res = indices.shape[:-1] + update\n",
        "    \"\"\"\n",
        "    #same Torch scatter_add_\n",
        "    scatter = tf.compat.v1.tensor_scatter_nd_add(tensor, indices, updates)\n",
        "    scatter = tf.compat.v1.reshape(scatter, shape=[tf.shape(original_tensor)[0], tf.shape(original_tensor)[1], -1])\n",
        "    return scatter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4nDlcp7zVxL"
      },
      "source": [
        "initial_learning_rate = 0.001\n",
        "# step = tf.Variable(0, trainable=False)\n",
        "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate,\n",
        "#     decay_steps=(num_examples//BATCH_SIZE) * 10,\n",
        "#     decay_rate=1.00,\n",
        "#     staircase=True)\n",
        "# wd = lambda: 1e-4 * lr_schedule(step)\n",
        "# optimizer = tfa.optimizers.AdamW(learning_rate=lr_schedule, clipnorm=1.0, weight_decay=wd)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  # real shape = (BATCH_SIZE, max_length_output)\n",
        "  # pred shape = (BATCH_SIZE, max_length_output, tar_vocab_size )\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "  loss = cross_entropy(y_true=real, y_pred=pred)\n",
        "  mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)  \n",
        "  loss = mask* loss\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss\n",
        "\n",
        "def coverage_loss(attn_dist, coverage):\n",
        "  min_val = tf.math.minimum(attn_dist, coverage)   # [B x L x T]   \n",
        "  loss = tf.math.reduce_sum(min_val, axis=1)            # [B x T]\n",
        "  avg_loss = tf.math.reduce_sum(loss) / (BATCH_SIZE * max_length_summaries)\n",
        "  return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBlb6syfB9vC"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN-av5PbB615"
      },
      "source": [
        "# saving weights\n",
        "def save_weights_in_drive(epoch):\n",
        "  if epoch!= 1:\n",
        "    os.remove(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-\" + str(epoch-1) + \".data-00000-of-00001\")\n",
        "    os.remove(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-\" + str(epoch-1) + \".index\")\n",
        "  shutil.copy2(\"/content/training_checkpoints/checkpoint\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  shutil.copy2(\"/content/training_checkpoints/ckpt-\" + str(epoch) + \".data-00000-of-00001\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  shutil.copy2(\"/content/training_checkpoints/ckpt-\" + str(epoch) + \".index\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')\n",
        "  # shutil.copy2(\"/content/drive/MyDrive/Pointer Generator Networks/coverage_weights.npy\", '/content/drive/MyDrive/Pointer Generator Networks/PGN weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t2BwZwmzn8e"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden, cov):\n",
        "  loss = 0\n",
        "  cov_loss = 0\n",
        "  cov_weight = 1.0\n",
        "  # 3 lists\n",
        "  final_dists = []\n",
        "  attn_dists = []\n",
        "  coverages = []\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "    dec_input = targ[ : , :-1 ]   # Ignore <end> token\n",
        "    real = targ[ : , 1: ]         # ignore <start> token\n",
        "    decoder_initial_state = decoder.initialize_hidden_state(BATCH_SIZE, enc_h, enc_c)\n",
        "    dec_emb = decoder.embedding(dec_input)\n",
        "    for t in range(max_length_summaries-1):\n",
        "      \n",
        "      input_t = dec_emb[:, t, :] \n",
        "      vocab_dist, attn_dist, context_vec, outputs, lstm_outputs, _, _ = decoder(dec_emb, decoder_initial_state, cov, enc_output, inp)\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "      attn_dist, vocab_dist = pointerGen(context_vec, input_t, outputs, vocab_dist, attn_dist)\n",
        "      \n",
        "      final_dist = scatter_add(vocab_dist, inp, attn_dist)\n",
        "      final_dist = tf.squeeze(final_dist, -1) \n",
        "      final_dists.append(final_dist)\n",
        "      attn_dists.append(attn_dist)\n",
        "      coverages.append(cov)\n",
        "\n",
        "    final_dists = tf.stack(final_dists, axis=-1)\n",
        "    attn_dists = tf.stack(attn_dists, axis=-1)\n",
        "    coverages = tf.stack(coverages, axis=-1)\n",
        "\n",
        "    final_dists = tf.reshape(final_dists, [BATCH_SIZE, max_length_summaries-1, vocab_size])\n",
        "    logits = lstm_outputs\n",
        "    loss = loss_function(real, final_dists)\n",
        "    # loss = loss / (max_length_summaries - 1)\n",
        "    cov_loss = coverage_loss(attn_dists, coverages)\n",
        "    loss = loss + cov_weight * cov_loss\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQIrH6hw0y_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "b01eb4d6-4667-40f1-cdbc-91e7cfce171c"
      },
      "source": [
        "EPOCHS = 40\n",
        "count = 1\n",
        "steps_per_epoch = num_examples//BATCH_SIZE\n",
        "val_steps_per_epoch = VAL_NUM_EXAMPLES//BATCH_SIZE\n",
        "# steps_per_epoch = 1\n",
        "if count == 1:\n",
        "  cov = np.zeros((BATCH_SIZE, max_length_articles))\n",
        "else:\n",
        "  cov = np.load(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/coverage_weights.npy\")\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  val_total_loss = 0\n",
        "  # print(enc_hidden[0].shape, enc_hidden[1].shape)\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden, cov)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print('Epoch {} Batch {} Loss {}'.format(count,\n",
        "                                                   batch,\n",
        "                                                   batch_loss))\n",
        "\n",
        "  for (val_batch, (val_inp, val_targ)) in enumerate(val_dataset.take(val_steps_per_epoch)):\n",
        "    val_batch_loss = eval_step(val_inp, val_targ, enc_hidden, cov)\n",
        "    val_total_loss += val_batch_loss\n",
        "  \n",
        "  # saving (checkpoint) the model every epoch\n",
        "  if (epoch + 1) % 1 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {}'.format(count,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Epoch {} Validation Loss {}'.format(count,\n",
        "                                      val_total_loss / val_steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  # print(\"Learning Rate: \" + str(optimizer.lr.initial_learning_rate))\n",
        "  train_losses.append(total_loss / steps_per_epoch)\n",
        "  eval_losses.append(val_total_loss / val_steps_per_epoch)\n",
        "  np.save(\"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/coverage_weights\", cov)\n",
        "  save_weights_in_drive(count)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 5.060651779174805\n",
            "Epoch 1 Batch 400 Loss 5.135815143585205\n",
            "Epoch 1 Batch 800 Loss 3.6768486499786377\n",
            "Epoch 1 Batch 1200 Loss 4.890878677368164\n",
            "Epoch 1 Batch 1600 Loss 5.3488030433654785\n",
            "Epoch 1 Batch 2000 Loss 5.146464824676514\n",
            "Epoch 1 Batch 2400 Loss 4.65659236907959\n",
            "Epoch 1 Batch 2800 Loss 4.635293960571289\n",
            "Epoch 1 Batch 3200 Loss 4.6459431648254395\n",
            "Epoch 1 Batch 3600 Loss 4.66724157333374\n",
            "Epoch 1 Batch 4000 Loss 4.369059085845947\n",
            "Epoch 1 Loss 4.786194801330566\n",
            "Time taken for 1 epoch 11062.720351457596 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.528799533843994\n",
            "Epoch 2 Batch 400 Loss 5.135815143585205\n",
            "Epoch 2 Batch 800 Loss 3.6768486499786377\n",
            "Epoch 2 Batch 1200 Loss 4.890878677368164\n",
            "Epoch 2 Batch 1600 Loss 5.3488030433654785\n",
            "Epoch 2 Batch 2000 Loss 5.146464824676514\n",
            "Epoch 2 Batch 2400 Loss 4.65659236907959\n",
            "Epoch 2 Batch 2800 Loss 4.635293960571289\n",
            "Epoch 2 Batch 3200 Loss 4.6459431648254395\n",
            "Epoch 2 Batch 3600 Loss 4.66724157333374\n",
            "Epoch 2 Batch 4000 Loss 4.369059085845947\n",
            "Epoch 2 Loss 4.785970211029053\n",
            "Time taken for 1 epoch 10925.267415046692 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 4.528799533843994\n",
            "Epoch 3 Batch 400 Loss 5.135815143585205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-239224873386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeEX_NeBBlHY"
      },
      "source": [
        "epochs = range(0,EPOCHS)\n",
        "plt.plot(epochs, train_losses, 'g', label='Training loss')\n",
        "plt.plot(epochs, eval_losses, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gI8_gCNJ_tQ"
      },
      "source": [
        "# Epoch 1 Loss 1.283766269683838\n",
        "def evaluate_sentence(sentence):\n",
        "    sentence = data.preprocess(sentence)\n",
        "    inputs = data.tokenizer.texts_to_sequences([sentence])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                          maxlen=max_length_articles,\n",
        "                                                          padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    inference_batch_size = inputs.shape[0]\n",
        "    encoder.trainable = False\n",
        "    decoder.trainable = False\n",
        "    enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units)), tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\n",
        "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
        "\n",
        "    decoded_seq = np.zeros((1,max_length_summaries))\n",
        "    decoded_seq[0,0]=word_index['<start>']\n",
        "    li_dec = decoded_seq\n",
        "    decoded_seq_word = '<start>'\n",
        "\n",
        "    li=[]\n",
        "    len_pred_summary = max_length_summaries - 2\n",
        "\n",
        "    dec_h = enc_h\n",
        "    dec_c = enc_c\n",
        "    dec_emb = decoder.embedding(decoded_seq)\n",
        "    ans_arr = []\n",
        "    cov = tf.zeros([1, max_length_articles], tf.float32)\n",
        "    for t in range(max_length_summaries-1):\n",
        "      decoder_initial_state = decoder.initialize_hidden_state(1, dec_h, dec_c)\n",
        "      input_t = dec_emb[:, t, :] \n",
        "      vocab_dist, attn_dist, context_vec, outputs, dec_h, dec_c = decoder(input_t, decoder_initial_state, cov, enc_out, inp)\n",
        "      cov = tf.cast(cov, dtype=tf.float32)\n",
        "      cov = cov + attn_dist\n",
        "      ans_arr.append(np.argmax(vocab_dist, axis = 1))\n",
        "    \n",
        "    encoder.trainable = True\n",
        "    decoder.trainable = True\n",
        "    return ans_arr\n",
        "\n",
        "def summarize(sentence):\n",
        "  result = evaluate_sentence(sentence)\n",
        "  result = data.tokenizer.sequences_to_texts(result)\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(\" \".join(result)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZgTmt3iQIZm",
        "outputId": "3b05f28f-7656-4390-e3b2-b5c5703f8437"
      },
      "source": [
        "test_sentence = \"There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahino’s nanny. Fletcher’s unveiling as the deadline day signing from Manchester United was almost eclipsed by the twenty-one-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahino’s senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford.\"\n",
        "summarize(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(127, 100000)\n",
            "(127,)\n",
            "Input: There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahino’s nanny. Fletcher’s unveiling as the deadline day signing from Manchester United was almost eclipsed by the twenty-one-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahino’s senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford.\n",
            "Predicted translation: ['sos the and and has and and and and sos and and and and and and and and and and and and and and and and and and and and and baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked baked and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqmqPOM81J-3",
        "outputId": "17ecebab-16cc-4d42-b7df-bcdaaa5e09dd"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/checkpoint\" \"/content/training_checkpoints/\"\n",
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-5.data-00000-of-00001\" \"/content/training_checkpoints/\"\n",
        "!cp \"/content/drive/MyDrive/Pointer Generator Networks/PGN weights/ckpt-5.index\" \"/content/training_checkpoints/\"\n",
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa34a631910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1IyuDbx5qXQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}